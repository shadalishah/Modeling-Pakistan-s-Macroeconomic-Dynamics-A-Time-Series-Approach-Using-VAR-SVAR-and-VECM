---
title: "Univariate and Multivariate Time Series Analysis of Real GDP, Inflation, Government Expenditure, Tax Revenue, and Interest Rate Using Quarterly Data (2010-2020) for Pakistan"
subtitle: "Real GDP, Inflation, Government Expenditure, Tax Revenue, and Interest Rate"
author: "Shad Ali Shah"
date: today
format:
  html:
    toc: true
    toc-depth: 2
    toc-location: left
    number-sections: true
    number-depth: 3
    code-fold: true
    code-tools: true
    code-summary: "Show code"
    theme: cosmo
    colorlinks: true
    link-citations: true
    df-print: kable
    fig-cap-location: bottom
    tbl-cap-location: top
    embed-resources: true
    self-contained: true
    page-layout: full
    grid:
      body-width: 1000px
    crossref:
      fig-title: "Figure"
      tbl-title: "Table"
      fig-prefix: "Fig."
      tbl-prefix: "Table"
      chapters: true
execute:
  echo: true
  warning: false
  message: false
  error: false
  cache: false
  keep-going: true
  fig-width: 6.5
  fig-height: 4
jupyter: python3
---

# **Introduction**
## ***Background of the Study***
Macroeconomic stability contineously play an important rule in sustainable economic growth, specially in developing economies where fiscal and monetary weakness many times amplify external shocks (Stiglitz, 2018). Pakistan's economy, is marked by persistent fiscal deficits, volatile inflation rates, and often balance of payments crises, clearly show the challenges faced by emerging markets in reaching macroeconomic equilibrium (Khan & Ahmed, 2021). Understanding the dynamic interdependencies among main macroeconomic variables—such as real GDP, government spending, tax revenue, inflation, and interest rates—is fundamental for formulating evidence-based policy interventions that promote stability and growth (Sims, 2022).
Traditional econometric techniques usually fail to capture the complicated feedback mechanisms and coincidence that characterize modern macroeconomic systems. Vector autoregression (VAR) models, together with their structural (SVAR) and cointegration-based (VECM) extensions, have emerged as powerful analytical tools for examining these multidimensional relationships (Stock & Watson, 2020). These methodologies empower researchers to capture causal linkages, trace policy transmission mechanisms, and forecast economic outcomes with large precision than univariate time series models (Lütkepohl, 2019). Even though their widespread adoption in advanced economies, rigid applications of VAR-based frameworks to Pakistan's macroeconomic dynamics remain limited, particularly in addressing fiscal-monetary interactions and their implications for price stability and economic growth.
Currently empirical evidence recomend that government expenditure shocks have asymmetric effects on output growth depending on the dominant fiscal space and monetary policy stance (Ramey, 2019). Similarly, the strongest of interest rate adjustments in controlling inflation is contingent upon the structure of the financial system and the degree of central bank credibility (Clarida, 2019). In Pakistan's context, where institutional weaknesses and political economy account often constrain policy effectiveness, a comprehensive time series analysis can provide valuable insights into how macroeconomic variables interact and respond to exogenous shocks. This study employs quarterly data spanning 2010 to 2020 to model Pakistan's macroeconomic dynamics using VAR, SVAR, and VECM techniques, thereby contributing to both theoretical understanding and practical policymaking.
Over the past decade, Pakistan has experienced significant macroeconomic volatility, with GDP growth fluctuating between 2% and 6%, inflation ranging from single digits to double digits, and government debt rising to over 70% of GDP (World Bank, 2021). The give and take between fiscal expansion through increased government spending and monetary tightening via higher interest rates has created policy dilemmas that underscore the need for empirical evidence on their combined effects. Moreover, Pakistan's low tax-to-GDP ratio—among the lowest in South Asia—limits fiscal space and constrains the government's ability to finance development expenditure without refuge to inflationary financing or external borrowing (International Monetary Fund, 2020). Understanding how these variables interact dynamically is crucial not only for short-term stabilization but also for long-term structural reforms aimed at improve revenue mobilization, improving expenditure efficiency, and maintaining price stability while fostering inclusive economic growth.

## ***Research Questions***

1.	What are the dynamic relationships and causal linkages among real GDP, government spending, tax revenue, inflation, and interest rates in Pakistan?
2.	How do structural shocks to fiscal and monetary policy variables affect macroeconomic stability and economic growth in the short run and long run?
3.	Do cointegrating relationships exist among Pakistan's key macroeconomic variables, and what are the implications for long-run equilibrium adjustments?

## ***Research Objectives***

1.	To evaluate the dynamic interactions and causal relationships among macroeconomic variables through Vector Autoregression (VAR) modeling, including Granger causality tests, impulse response functions, and forecast error variance decomposition.
2.	To identify the structural transmission mechanisms of fiscal and monetary policy shocks using Structural VAR (SVAR) with appropriate identification restrictions.
3.	To assess the existence and nature of long-run equilibrium relationships among macroeconomic variables through cointegration analysis and Vector Error Correction Model (VECM) estimation.

## ***Significance of the Study***

This study examines critical policy levers in Pakistan's economy—real GDP, government spending, tax revenue, inflation, and interest rates—that directly influence economic outcomes and citizen welfare, determining employment, infrastructure development, fiscal space, purchasing power, and investment decisions with particularly significant impacts on low-income households and debt sustainability. Using advanced time series techniques, the study analyzes dynamic interactions among these variables to provide empirical evidence for coordinated fiscal-monetary policy decisions at the State Bank of Pakistan and Ministry of Finance, ultimately contributing to macroeconomic stability, sustainable growth, and improved living standards across Pakistan's population.

# **Rsearch Methods**
This study used a quantitative time-series methodology to investigate Pakistan's macroeconomic dynamics, using quarterly data from 2010 to 2020. The data was sourced from the Pakistan Bureau of Statistics and the State Bank of Pakistan. There were five major variables: real GDP (log-transformed), government spending, tax revenue (Net_Revenue), inflation (CPI_Quarterly_Avg), and interest rates. Since real GDP, government spending, interest rates, and net revenue were previously reported annually, they were converted to quarterly frequency using the Chow-Lin temporal disaggregation method, The Chow-Lin technique disaggregates annual macroeconomic data by exploiting the co-movement between target variables and related quarterly indicators that share common economic drivers. For Real GDP, indicators like industrial production or employment capture business cycles; for Government Spending and Tax Revenue, quarterly fiscal data reflects actual disbursement and collection patterns. Interest Rates use quarterly money market rates that track credit conditions, while Inflation uses quarterly CPI data capturing actual price dynamics. This method is economically superior to mechanical interpolation because it preserves structural relationships between variables and their determinants, ensures aggregation consistency (quarterly values sum to annual totals), and provides statistically optimal estimates. The approach respects underlying economic mechanisms rather than imposing arbitrary temporal patterns, which preserves the temporal consistency and flow characteristics of economic aggregates (Chow & Lin, 1971). The CPI quarterly average was calculated by averaging three monthly CPI figures from each quarter. 

The analytical framework proceeded in stages. First, the researchers performed univariate time-series analysis through time plots and classical decomposition which separated the data into trend and seasonal and irregular components and followed by ACF and PACF diagnostics to detect basic data patterns and possible AR and MA processes (Box & Jenkins, 1976). Second, stationarity was assessed using the Augmented Dickey-Fuller (ADF) and Kwiatkowski-Phillips-Schmidt-Shin (KPSS) tests with four lags under constant and trend specifications (Dickey & Fuller, 1981; Kwiatkowski et al., 1992). The results showed that logGDP and CPI_Quarterly_Avg and government_spending existed as first-order integrated processes I(1) but interest_rate and Net_Revenue stayed as stationary processes I(0).

Based on stationarity properties, appropriate ARIMA models were estimated for each variable, with 
final model selection guided by root mean square error (RMSE) minimization (Hyndman & Athanasopoulos, 2018). The researchers chose to analyze the data through first-differenced Vector Autoregression (VAR) models because the variables contained different integration levels and lacked cointegration relationships (Lütkepohl, 2005). The researchers used Structural VAR (SVAR) models with short-run identification restrictions to analyze the dynamic mechanisms of policy transmission (Sims, 1980). The researchers used this methodical process to study the relationships between major economic indicators in Pakistan.

# **Results and Discussions**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf
from statsmodels.tsa.seasonal import seasonal_decompose

# Load data
file_path = r"E:\term_paper\final_dataset_quarterly_formal.xlsx"
df = pd.read_excel(file_path, sheet_name="quarterly", header=0)
df['Date'] = pd.PeriodIndex(df['Date'], freq='Q').to_timestamp()
df.set_index('Date', inplace=True)
df.sort_index(inplace=True)
```

```{python}
head = df.head()
print(head)  # Display the first few rows to verify data loading
```

## Time plots of GDP

```{python}
import pandas as pd
import plotly.graph_objects as go

# Your data is already loaded
# Let's create the beautiful plot

fig = go.Figure()

# Add GDP line with gradient fill
fig.add_trace(go.Scatter(
    x=df.index,
    y=df['gdp'],
    mode='lines',
    name='GDP',
    line=dict(color='#3498db', width=3),
    fill='tozeroy',
    fillcolor='rgba(52, 152, 219, 0.2)',
    hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br>' +
                  '<b>GDP</b>: PKR %{y:,.0f}<br>' +
                  '<extra></extra>'
))

fig.update_layout(
    title={
        'text': '<b>Pakistan Quarterly GDP Plot</b><br>' +
                '<sub style="font-size:12px;">Showing Economic Growth Trend Over Time</sub>',
        'y': 0.95,
        'x': 0.5,
        'xanchor': 'center',
        'yanchor': 'top',
        'font': dict(size=22, color='#1a1a1a', family='Arial Black')
    },
    xaxis=dict(
        title=dict(
            text='<b>Time Period (Quarterly)</b>',
            font=dict(size=14, color='#2c3e50', family='Arial')
        ),
        showgrid=True,
        gridwidth=1,
        gridcolor='rgba(200, 200, 200, 0.3)',
        zeroline=False
    ),
    yaxis=dict(
        title=dict(
            text='<b>Gross Domestic Product (PKR)</b>',
            font=dict(size=14, color='#2c3e50', family='Arial')
        ),
        showgrid=True,
        gridwidth=1,
        gridcolor='rgba(200, 200, 200, 0.3)',
        zeroline=True,
        tickformat=',.0f'
    ),
    plot_bgcolor='#ffffff',
    paper_bgcolor='#f5f5f5',
    hovermode='x unified',
    font=dict(family="Arial", size=11),
    showlegend=False,
    height=550,
    margin=dict(l=100, r=50, t=120, b=100)
)

# Add data source at bottom right
fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.12,
    xanchor='right', yanchor='top',
    font=dict(size=11, color='#7f8c8d'),
    showarrow=False,
    bgcolor='rgba(255, 255, 255, 0.8)',
    bordercolor='#bdc3c7',
    borderwidth=1,
    borderpad=4
)

# Add watermark
fig.add_annotation(
    text='Pakistan Bureau of Statistics',
    xref='paper', yref='paper',
    x=0.5, y=0.5,
    xanchor='center', yanchor='middle',
    font=dict(size=40, color='rgba(150, 150, 150, 0.1)', family='Arial Black'),
    showarrow=False
)

# THIS IS IMPORTANT - Show the plot
fig.show()

# Optional: Save as HTML
fig.write_html("pakistan_gdp_plot.html")

```

The GDP plot shows the trend of Pakistan's quarterly GDP over time, highlighting periods of growth and decline. As a whole, the GDP has shown an upward trend, indicating economic growth, with some fluctuations that may correspond to economic events or policies.

## **Growth Rate Analysis for GDP**

```{python}
import pandas as pd
import numpy as np
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# ============================================
# CALCULATE GROWTH RATES FIRST
# ============================================

df['gdp_qoq_growth'] = ((df['gdp'] - df['gdp'].shift(1)) / df['gdp'].shift(1)) * 100
df['gdp_yoy_growth'] = ((df['gdp'] - df['gdp'].shift(4)) / df['gdp'].shift(4)) * 100

# ============================================
# SIDE-BY-SIDE LAYOUT (STOCK & WATSON STYLE)
# ============================================

fig = make_subplots(
    rows=1, cols=2,
    subplot_titles=('Quarter-on-Quarter (QoQ) Growth Rate', 
                    'Year-on-Year (YoY) Growth Rate'),
    horizontal_spacing=0.12,
    column_widths=[0.5, 0.5]
)

# LEFT: QoQ Growth Rate
colors_qoq = ['green' if x > 0 else 'red' for x in df['gdp_qoq_growth']]
fig.add_trace(
    go.Bar(
        x=df.index,
        y=df['gdp_qoq_growth'],
        name='QoQ Growth',
        marker_color=colors_qoq,
        hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br>' +
                      '<b>QoQ Growth</b>: %{y:.2f}%<br>' +
                      '<extra></extra>'
    ),
    row=1, col=1
)

# RIGHT: YoY Growth Rate
colors_yoy = ['green' if x > 0 else 'red' for x in df['gdp_yoy_growth']]
fig.add_trace(
    go.Bar(
        x=df.index,
        y=df['gdp_yoy_growth'],
        name='YoY Growth',
        marker_color=colors_yoy,
        hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br>' +
                      '<b>YoY Growth</b>: %{y:.2f}%<br>' +
                      '<extra></extra>'
    ),
    row=1, col=2
)

# Add zero lines
fig.add_hline(y=0, line_dash="dash", line_color="black", line_width=1, row=1, col=1)
fig.add_hline(y=0, line_dash="dash", line_color="black", line_width=1, row=1, col=2)

# Update layout (Stock & Watson style - compact)
fig.update_layout(
    title={
        'text': '<b>Pakistan GDP Growth Rate Analysis</b><br>' +
                '<sub>Quarterly Growth Patterns (QoQ vs YoY)</sub>',
        'y':0.96,
        'x':0.5,
        'xanchor': 'center',
        'yanchor': 'top',
        'font': dict(size=18, color='#1a1a1a', family='Times New Roman')
    },
    showlegend=False,
    height=400,  # Reduced height for compact view
    width=1200,  # Wider for side-by-side
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

# Update axes (both columns)
fig.update_xaxes(
    title_text="Time Period",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.update_yaxes(
    title_text="Growth Rate (%)",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.12,
    xanchor='right', yanchor='top',
    font=dict(size=10, color='#7f8c8d'),
    showarrow=False
)

fig.show()
```

The GDP growth rate plot illustrates the percentage change in Pakistan's GDP from one quarter to the next. This visualization helps identify periods of rapid economic expansion as well as slowdowns or contractions. Notably, there are spikes in growth rates during certain quarters like 2016 to 2018, which may be linked to specific economic reforms or external factors influencing the economy.

## **Seasonal Decomposition of GDP**

```{python}
import pandas as pd
import numpy as np
from plotly.subplots import make_subplots
import plotly.graph_objects as go
from statsmodels.tsa.seasonal import seasonal_decompose

# ============================================
# SEASONAL DECOMPOSITION
# ============================================

decomposition = seasonal_decompose(df['gdp'], model='additive', period=4)
df['gdp_trend'] = decomposition.trend
df['gdp_residual'] = decomposition.resid

# ============================================
# SIDE-BY-SIDE LAYOUT (STOCK & WATSON STYLE)
# ============================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=('Original GDP', 'Trend Component', 
                    'Residual Component', ''),
    vertical_spacing=0.12,
    horizontal_spacing=0.12,
    row_heights=[0.5, 0.5],
    column_widths=[0.5, 0.5],
    specs=[[{}, {}], [{}, None]]  # Last cell empty
)

# TOP LEFT: Original GDP
fig.add_trace(
    go.Scatter(
        x=df.index, y=df['gdp'],
        mode='lines',
        name='Original',
        line=dict(color='black', width=2),
        hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br><b>GDP</b>: %{y:,.0f}<br><extra></extra>'
    ),
    row=1, col=1
)

# TOP RIGHT: Trend
fig.add_trace(
    go.Scatter(
        x=df.index, y=df['gdp_trend'],
        mode='lines',
        name='Trend',
        line=dict(color='black', width=2),
        hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br><b>Trend</b>: %{y:,.0f}<br><extra></extra>'
    ),
    row=1, col=2
)

# BOTTOM LEFT: Residual
fig.add_trace(
    go.Scatter(
        x=df.index, y=df['gdp_residual'],
        mode='lines',
        name='Residual',
        line=dict(color='black', width=2),
        hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br><b>Residual</b>: %{y:,.0f}<br><extra></extra>'
    ),
    row=2, col=1
)

# Add zero line for residual
fig.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1, row=2, col=1)

# Update layout (Stock & Watson style)
fig.update_layout(
    title={
        'text': '<b>Pakistan GDP Decomposition Analysis</b><br>' +
                '<sub>Original, Trend, and Residual Components</sub>',
        'y':0.96,
        'x':0.5,
        'xanchor': 'center',
        'yanchor': 'top',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False,
    height=600,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

# Update axes (Stock & Watson style - minimal)
fig.update_xaxes(
    title_text="Time Period",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.update_yaxes(
    title_text="GDP (PKR Billions)",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

# Specific y-axis title for residual
fig.update_yaxes(title_text="Residual", row=2, col=1)

fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.08,
    xanchor='right', yanchor='top',
    font=dict(size=10, color='gray'),
    showarrow=False
)

fig.show()
```

The time series decomposition plot breaks down Pakistan's GDP into its constituent components: trend, and residual. The trend component confirms the overall upward trajectory of GDP. The residual component captures irregular variations that are not explained by the trend or seasonal patterns.

## **ACF and PACF level for level GDP for AR Process**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf
from statsmodels.stats.diagnostic import acorr_ljungbox

# ============================================
# CREATE LOG GDP (LEVEL DATA)
# ============================================

df['loggdp'] = np.log(df['gdp'])

# ============================================
# ACF AND PACF FOR LEVEL DATA (loggdp)
# ============================================

# Use level data (loggdp without differencing)
level_series = df['loggdp'].dropna()

# Calculate ACF
acf_level = acf(level_series, nlags=20, alpha=0.05)
acf_corr_level = acf_level[0]

# Calculate PACF
pacf_level = pacf(level_series, nlags=20, alpha=0.05)
pacf_corr_level = pacf_level[0]

# Confidence level
confidence_level_level = 1.96 / np.sqrt(len(level_series))

# ============================================
# SIDE-BY-SIDE VISUALIZATION (STOCK & WATSON STYLE)
# ============================================

fig_level = make_subplots(
    rows=1, cols=2,
    subplot_titles=('ACF - Level Data (logGDP)', 
                    'PACF - Level Data (logGDP)'),
    horizontal_spacing=0.12,
    column_widths=[0.5, 0.5]
)

lags_level = list(range(len(acf_corr_level)))
pacf_lags_level = list(range(len(pacf_corr_level)))

# LEFT: ACF Plot
fig_level.add_trace(
    go.Bar(
        x=lags_level,
        y=acf_corr_level,
        name='ACF',
        marker_color='black',
        hovertemplate='<b>Lag</b>: %{x}<br><b>ACF</b>: %{y:.4f}<br><extra></extra>'
    ),
    row=1, col=1
)
fig_level.add_hline(y=confidence_level_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig_level.add_hline(y=-confidence_level_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig_level.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=1)

# RIGHT: PACF Plot
fig_level.add_trace(
    go.Bar(
        x=pacf_lags_level,
        y=pacf_corr_level,
        name='PACF',
        marker_color='black',
        hovertemplate='<b>Lag</b>: %{x}<br><b>PACF</b>: %{y:.4f}<br><extra></extra>'
    ),
    row=1, col=2
)
fig_level.add_hline(y=confidence_level_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig_level.add_hline(y=-confidence_level_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig_level.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=2)

# Update layout (Stock & Watson style)
fig_level.update_layout(
    title={
        'text': '<b>Pakistan GDP: ACF and PACF Analysis (Level Data)</b><br>' +
                '<sub>logGDP - No Differencing</sub>',
        'y':0.96,
        'x':0.5,
        'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False,
    height=400,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

# Update axes (Stock & Watson style)
fig_level.update_xaxes(
    title_text="Lag",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig_level.update_yaxes(
    title_text="Autocorrelation",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8),
    range=[-1, 1],
    row=1, col=1
)

fig_level.update_yaxes(
    title_text="Partial Autocorrelation",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8),
    range=[-1, 1],
    row=1, col=2
)

fig_level.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.12,
    xanchor='right', yanchor='top',
    font=dict(size=10, color='gray'),
    showarrow=False
)

fig_level.show()

```

## **ACF and PACF Analysis for logGDP on level for MA Process**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf
from statsmodels.stats.diagnostic import acorr_ljungbox

# ============================================
# CREATE LOG GDP (LEVEL DATA)
# ============================================

df['loggdp'] = np.log(df['gdp'])

# ============================================
# ACF AND PACF FOR MA PROCESS (Level Data)
# ============================================

# Use level data (loggdp without differencing)
ma_series = df['loggdp'].dropna()

# Calculate ACF
acf_ma = acf(ma_series, nlags=20, alpha=0.05)
acf_corr_ma = acf_ma[0]

# Calculate PACF
pacf_ma = pacf(ma_series, nlags=20, alpha=0.05)
pacf_corr_ma = pacf_ma[0]

# Confidence level
confidence_level_ma = 1.96 / np.sqrt(len(ma_series))

# ============================================
# SIDE-BY-SIDE VISUALIZATION (STOCK & WATSON STYLE)
# ============================================

fig_ma = make_subplots(
    rows=1, cols=2,
    subplot_titles=('ACF - MA Process (logGDP Level Data)', 
                    'PACF - MA Process (logGDP Level Data)'),
    horizontal_spacing=0.12,
    column_widths=[0.5, 0.5]
)

lags_ma = list(range(len(acf_corr_ma)))
pacf_lags_ma = list(range(len(pacf_corr_ma)))

# LEFT: ACF Plot (For MA identification - look for cutoff)
fig_ma.add_trace(
    go.Bar(
        x=lags_ma,
        y=acf_corr_ma,
        name='ACF',
        marker_color='black',
        hovertemplate='<b>Lag</b>: %{x}<br><b>ACF</b>: %{y:.4f}<br><extra></extra>'
    ),
    row=1, col=1
)
fig_ma.add_hline(y=confidence_level_ma, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig_ma.add_hline(y=-confidence_level_ma, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig_ma.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=1)

# RIGHT: PACF Plot (For MA identification - should decay gradually)
fig_ma.add_trace(
    go.Bar(
        x=pacf_lags_ma,
        y=pacf_corr_ma,
        name='PACF',
        marker_color='black',
        hovertemplate='<b>Lag</b>: %{x}<br><b>PACF</b>: %{y:.4f}<br><extra></extra>'
    ),
    row=1, col=2
)
fig_ma.add_hline(y=confidence_level_ma, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig_ma.add_hline(y=-confidence_level_ma, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig_ma.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=2)

# Update layout (Stock & Watson style)
fig_ma.update_layout(
    title={
        'text': '<b>Pakistan GDP: ACF and PACF Analysis (MA Process)</b><br>' +
                '<sub>Moving Average Pattern - logGDP Level Series</sub>',
        'y':0.96,
        'x':0.5,
        'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False,
    height=400,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

# Update axes (Stock & Watson style)
fig_ma.update_xaxes(
    title_text="Lag",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig_ma.update_yaxes(
    title_text="Autocorrelation",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8),
    range=[-1, 1],
    row=1, col=1
)

fig_ma.update_yaxes(
    title_text="Partial Autocorrelation",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8),
    range=[-1, 1],
    row=1, col=2
)

fig_ma.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.12,
    xanchor='right', yanchor='top',
    font=dict(size=10, color='gray'),
    showarrow=False
)

fig_ma.show()

```

## **AR Process and MA Process Analysis for logGDP differencing 1**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf

# Create first difference
df['loggdp'] = np.log(df['gdp'])
df['loggdp_diff'] = df['loggdp'].diff()
ar_series = df['loggdp_diff'].dropna()

# Calculate ACF and PACF
acf_vals = acf(ar_series, nlags=20)
pacf_vals = pacf(ar_series, nlags=20)
conf_level = 1.96 / np.sqrt(len(ar_series))

# Print values
print("=" * 70)
print("AR PROCESS - First Difference logGDP")
print("=" * 70)
print("\nPACF Values (first 10 lags):")
for i in range(min(11, len(pacf_vals))):
    print(f"Lag {i}: {pacf_vals[i]:.4f}")

# Identify AR order
ar_lags = [i for i in range(1, 11) if abs(pacf_vals[i]) > conf_level]
print(f"\nSignificant PACF lags: {ar_lags}")
print(f"Suggested AR order (p): {ar_lags[0] if ar_lags else 0}")

# ============================================
# SIDE-BY-SIDE PLOT (STOCK & WATSON STYLE)
# ============================================

fig = make_subplots(
    rows=1, cols=2, 
    subplot_titles=('ACF - AR Process', 'PACF - AR Process'),
    horizontal_spacing=0.12,
    column_widths=[0.5, 0.5]
)

# LEFT: ACF Plot
fig.add_trace(
    go.Bar(
        x=list(range(len(acf_vals))), 
        y=acf_vals, 
        marker_color='black', 
        name='ACF',
        hovertemplate='<b>Lag</b>: %{x}<br><b>ACF</b>: %{y:.4f}<br><extra></extra>'
    ), 
    row=1, col=1
)
fig.add_hline(y=conf_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig.add_hline(y=-conf_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=1)

# RIGHT: PACF Plot
fig.add_trace(
    go.Bar(
        x=list(range(len(pacf_vals))), 
        y=pacf_vals, 
        marker_color='black', 
        name='PACF',
        hovertemplate='<b>Lag</b>: %{x}<br><b>PACF</b>: %{y:.4f}<br><extra></extra>'
    ), 
    row=1, col=2
)
fig.add_hline(y=conf_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig.add_hline(y=-conf_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=2)

# Update layout (Stock & Watson style)
fig.update_layout(
    title={
        'text': '<b>AR Process - First Difference logGDP</b><br>' +
                '<sub>Autoregressive Pattern Identification</sub>',
        'y':0.96,
        'x':0.5,
        'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False,
    height=400,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

# Update axes (Stock & Watson style)
fig.update_xaxes(
    title_text="Lag",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.update_yaxes(
    title_text="Autocorrelation",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8),
    range=[-1, 1],
    row=1, col=1
)

fig.update_yaxes(
    title_text="Partial Autocorrelation",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8),
    range=[-1, 1],
    row=1, col=2
)

fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.12,
    xanchor='right', yanchor='top',
    font=dict(size=10, color='gray'),
    showarrow=False
)

fig.show()

print("=" * 70)
```

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf

# Create first difference
df['loggdp'] = np.log(df['gdp'])
df['loggdp_diff'] = df['loggdp'].diff()
ma_series = df['loggdp_diff'].dropna()

# Calculate ACF and PACF
acf_vals = acf(ma_series, nlags=20)
pacf_vals = pacf(ma_series, nlags=20)
conf_level = 1.96 / np.sqrt(len(ma_series))

# ============================================
# SIDE-BY-SIDE PLOT (STOCK & WATSON STYLE)
# ============================================

fig = make_subplots(
    rows=1, cols=2, 
    subplot_titles=('ACF - MA Process', 'PACF - MA Process'),
    horizontal_spacing=0.12,
    column_widths=[0.5, 0.5]
)

# LEFT: ACF Plot
fig.add_trace(
    go.Bar(
        x=list(range(len(acf_vals))), 
        y=acf_vals, 
        marker_color='black', 
        name='ACF',
        hovertemplate='<b>Lag</b>: %{x}<br><b>ACF</b>: %{y:.4f}<br><extra></extra>'
    ), 
    row=1, col=1
)
fig.add_hline(y=conf_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig.add_hline(y=-conf_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=1)

# RIGHT: PACF Plot
fig.add_trace(
    go.Bar(
        x=list(range(len(pacf_vals))), 
        y=pacf_vals, 
        marker_color='black', 
        name='PACF',
        hovertemplate='<b>Lag</b>: %{x}<br><b>PACF</b>: %{y:.4f}<br><extra></extra>'
    ), 
    row=1, col=2
)
fig.add_hline(y=conf_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig.add_hline(y=-conf_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=2)

# Update layout (Stock & Watson style)
fig.update_layout(
    title={
        'text': '<b>MA Process - First Difference logGDP</b><br>' +
                '<sub>Moving Average Pattern Identification</sub>',
        'y':0.96,
        'x':0.5,
        'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False,
    height=400,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

# Update axes (Stock & Watson style)
fig.update_xaxes(
    title_text="Lag",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.update_yaxes(
    title_text="Autocorrelation",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8),
    range=[-1, 1],
    row=1, col=1
)

fig.update_yaxes(
    title_text="Partial Autocorrelation",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8),
    range=[-1, 1],
    row=1, col=2
)

fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.12,
    xanchor='right', yanchor='top',
    font=dict(size=10, color='gray'),
    showarrow=False
)

fig.show()

print("=" * 70)
```

The loggdp Series is STATIONARY on (First Difference) because ACF eponentioally go to zero but this informal method is not enough to conclude that the series is stationary. We need to perform formal tests like the Augmented Dickey-Fuller (ADF) test or the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test to confirm stationarity.

## **ADF and KPSS test for loggdp first difference**

```{python}
from statsmodels.tsa.stattools import adfuller, kpss
import pandas as pd
import numpy as np

# ============================================
# PREPARE DATA: ORIGINAL, D1, D2
# ============================================

df['log_gdp_diff'] = df['log_gdp'].diff()
df['log_gdp_diff2'] = df['log_gdp_diff'].diff()

# Test data
original = df['log_gdp'].dropna()
diff1 = df['log_gdp_diff'].dropna()
diff2 = df['log_gdp_diff2'].dropna()

# ============================================
# RUN ALL TESTS (MAX 4 LAGS)
# ============================================

def run_all_tests(series):
    """Run ADF and KPSS tests with all specifications (max 4 lags)"""
    results = {}
    
    # ADF Tests (maxlag=4)
    adf_ct = adfuller(series, maxlag=4, autolag='AIC', regression='ct')
    adf_c = adfuller(series, maxlag=4, autolag='AIC', regression='c')
    adf_n = adfuller(series, maxlag=4, autolag='AIC', regression='n')
    
    results['ADF_ct'] = {'stat': adf_ct[0], 'pval': adf_ct[1], 'lags': adf_ct[2], 'stationary': adf_ct[1] < 0.05}
    results['ADF_c'] = {'stat': adf_c[0], 'pval': adf_c[1], 'lags': adf_c[2], 'stationary': adf_c[1] < 0.05}
    results['ADF_n'] = {'stat': adf_n[0], 'pval': adf_n[1], 'lags': adf_n[2], 'stationary': adf_n[1] < 0.05}
    
    # KPSS Tests (nlags=4)
    kpss_ct = kpss(series, regression='ct', nlags=4)
    kpss_c = kpss(series, regression='c', nlags=4)
    
    results['KPSS_ct'] = {'stat': kpss_ct[0], 'pval': kpss_ct[1], 'lags': 4, 'stationary': kpss_ct[1] > 0.05}
    results['KPSS_c'] = {'stat': kpss_c[0], 'pval': kpss_c[1], 'lags': 4, 'stationary': kpss_c[1] > 0.05}
    
    return results

# Run tests for all series
results_orig = run_all_tests(original)
results_d1 = run_all_tests(diff1)
results_d2 = run_all_tests(diff2)

# ============================================
# CREATE SUMMARY TABLE
# ============================================

table_data = []

for series_name, results in [
    ('Original Log(GDP)', results_orig),
    ('First Difference', results_d1),
    ('Second Difference', results_d2)
]:
    # ADF with Constant + Trend
    table_data.append({
        'Series': series_name,
        'Test': 'ADF',
        'Specification': 'Constant + Trend',
        'Statistic': f"{results['ADF_ct']['stat']:.4f}",
        'P-value': f"{results['ADF_ct']['pval']:.4f}",
        'Lags': results['ADF_ct']['lags'],
        'Result': '✓' if results['ADF_ct']['stationary'] else '✗'
    })
    
    # ADF with Constant only
    table_data.append({
        'Series': series_name,
        'Test': 'ADF',
        'Specification': 'Constant',
        'Statistic': f"{results['ADF_c']['stat']:.4f}",
        'P-value': f"{results['ADF_c']['pval']:.4f}",
        'Lags': results['ADF_c']['lags'],
        'Result': '✓' if results['ADF_c']['stationary'] else '✗'
    })
    
    # ADF with None
    table_data.append({
        'Series': series_name,
        'Test': 'ADF',
        'Specification': 'None',
        'Statistic': f"{results['ADF_n']['stat']:.4f}",
        'P-value': f"{results['ADF_n']['pval']:.4f}",
        'Lags': results['ADF_n']['lags'],
        'Result': '✓' if results['ADF_n']['stationary'] else '✗'
    })
    
    # KPSS with Constant + Trend
    table_data.append({
        'Series': series_name,
        'Test': 'KPSS',
        'Specification': 'Constant + Trend',
        'Statistic': f"{results['KPSS_ct']['stat']:.4f}",
        'P-value': f"{results['KPSS_ct']['pval']:.4f}",
        'Lags': results['KPSS_ct']['lags'],
        'Result': '✓' if results['KPSS_ct']['stationary'] else '✗'
    })
    
    # KPSS with Constant only
    table_data.append({
        'Series': series_name,
        'Test': 'KPSS',
        'Specification': 'Constant',
        'Statistic': f"{results['KPSS_c']['stat']:.4f}",
        'P-value': f"{results['KPSS_c']['pval']:.4f}",
        'Lags': results['KPSS_c']['lags'],
        'Result': '✓' if results['KPSS_c']['stationary'] else '✗'
    })

# Create DataFrame
summary_table = pd.DataFrame(table_data)

# Print table
print("=" * 110)
print("STATIONARITY TEST RESULTS (MAX 4 LAGS)")
print("=" * 110)
print(summary_table.to_string(index=False))
print("=" * 110)
print("Legend: ✓ = Stationary  |  ✗ = Non-Stationary")
print("=" * 110)
```

we take decisions on they basis of KPSS test and conclude that the loggdp series is stationary on first difference with drift and 4 lags. Hence we can proceed with ARIMA modeling on loggdp series.

## **ARIMA (1,1,1) model for loggdp series**

```{python}
from statsmodels.tsa.arima.model import ARIMA
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# ============================================
# PREPARE DATA
# ============================================

df['loggdp'] = np.log(df['gdp'])
data = df['loggdp'].dropna()

# Split data: train (all but last 4) and test (last 4 for validation)
train_data = data[:-4]
test_data = data[-4:]

print("=" * 80)
print("ARIMA MODEL COMPARISON FOR logGDP")
print("=" * 80)
print(f"Total observations: {len(data)}")
print(f"Training observations: {len(train_data)}")
print(f"Test observations: {len(test_data)}")
print("=" * 80)

# ============================================
# FIT ARIMA(1,1,1) MODEL
# ============================================

print("\n" + "=" * 80)
print("FITTING ARIMA(1,1,1) MODEL")
print("=" * 80)

model_111 = ARIMA(train_data, order=(1, 1, 1))
results_111 = model_111.fit()

# Forecast 4 quarters ahead
forecast_111 = results_111.get_forecast(steps=4)
forecast_values_111 = forecast_111.predicted_mean
forecast_ci_111 = forecast_111.conf_int(alpha=0.05)

# Calculate RMSE
rmse_111 = np.sqrt(mean_squared_error(test_data, forecast_values_111))

print(f"\nAIC: {results_111.aic:.4f}")
print(f"BIC: {results_111.bic:.4f}")
print(f"RMSE (Root Mean Squared Error): {rmse_111:.6f}")

# ============================================
# FIT ARIMA(2,1,2) MODEL
# ============================================

print("\n" + "=" * 80)
print("FITTING ARIMA(2,1,2) MODEL")
print("=" * 80)

model_212 = ARIMA(train_data, order=(2, 1, 2))
results_212 = model_212.fit()

# Forecast 4 quarters ahead
forecast_212 = results_212.get_forecast(steps=4)
forecast_values_212 = forecast_212.predicted_mean
forecast_ci_212 = forecast_212.conf_int(alpha=0.05)

# Calculate RMSE
rmse_212 = np.sqrt(mean_squared_error(test_data, forecast_values_212))

print(f"\nAIC: {results_212.aic:.4f}")
print(f"BIC: {results_212.bic:.4f}")
print(f"RMSE (Root Mean Squared Error): {rmse_212:.6f}")

# ============================================
# MODEL COMPARISON TABLE
# ============================================

print("\n" + "=" * 80)
print("MODEL COMPARISON")
print("=" * 80)
comparison_df = pd.DataFrame({
    'Model': ['ARIMA(1,1,1)', 'ARIMA(2,1,2)'],
    'AIC': [results_111.aic, results_212.aic],
    'BIC': [results_111.bic, results_212.bic],
    'RMSE': [rmse_111, rmse_212]
})
print(comparison_df.to_string(index=False))
print("=" * 80)

# Determine best model
best_model = 'ARIMA(1,1,1)' if rmse_111 < rmse_212 else 'ARIMA(2,1,2)'
print(f"\n✓ Best Model (based on RMSE): {best_model}")
print("=" * 80)

# ============================================
# SIDE-BY-SIDE VISUALIZATION (STOCK & WATSON STYLE)
# ============================================

fig = make_subplots(
    rows=1, cols=2,
    subplot_titles=(f'ARIMA(1,1,1) | RMSE: {rmse_111:.4f}', 
                    f'ARIMA(2,1,2) | RMSE: {rmse_212:.4f}'),
    horizontal_spacing=0.10,
    column_widths=[0.5, 0.5]
)

# ============================================
# LEFT: ARIMA(1,1,1)
# ============================================

# Training data
fig.add_trace(go.Scatter(
    x=train_data.index.astype(str),
    y=train_data.values,
    mode='lines',
    name='Training',
    line=dict(color='black', width=1.5),
    showlegend=True,
    legendgroup='group1',
    hovertemplate='<b>Train</b>: %{y:.4f}<extra></extra>'
), row=1, col=1)

# Actual test data
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=test_data.values,
    mode='lines+markers',
    name='Actual',
    line=dict(color='black', width=2),
    marker=dict(size=6, color='black'),
    showlegend=True,
    legendgroup='group1',
    hovertemplate='<b>Actual</b>: %{y:.4f}<extra></extra>'
), row=1, col=1)

# Forecast
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_values_111.values,
    mode='lines+markers',
    name='Forecast (1,1,1)',
    line=dict(color='gray', width=1.5, dash='dash'),
    marker=dict(size=6, color='gray', symbol='x'),
    showlegend=True,
    legendgroup='group1',
    hovertemplate='<b>Forecast</b>: %{y:.4f}<extra></extra>'
), row=1, col=1)

# Confidence interval
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_111.iloc[:, 1].values,
    fill=None,
    mode='lines',
    line=dict(color='lightgray', width=0.5, dash='dot'),
    showlegend=False,
    hoverinfo='skip'
), row=1, col=1)

fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_111.iloc[:, 0].values,
    fill='tonexty',
    mode='lines',
    line=dict(color='lightgray', width=0.5, dash='dot'),
    fillcolor='rgba(128,128,128,0.1)',
    showlegend=False,
    hoverinfo='skip'
), row=1, col=1)

# ============================================
# RIGHT: ARIMA(2,1,2)
# ============================================

# Training data
fig.add_trace(go.Scatter(
    x=train_data.index.astype(str),
    y=train_data.values,
    mode='lines',
    name='Training',
    line=dict(color='black', width=1.5),
    showlegend=False,
    legendgroup='group2',
    hovertemplate='<b>Train</b>: %{y:.4f}<extra></extra>'
), row=1, col=2)

# Actual test data
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=test_data.values,
    mode='lines+markers',
    name='Actual',
    line=dict(color='black', width=2),
    marker=dict(size=6, color='black'),
    showlegend=False,
    legendgroup='group2',
    hovertemplate='<b>Actual</b>: %{y:.4f}<extra></extra>'
), row=1, col=2)

# Forecast
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_values_212.values,
    mode='lines+markers',
    name='Forecast (2,1,2)',
    line=dict(color='gray', width=1.5, dash='dash'),
    marker=dict(size=6, color='gray', symbol='diamond'),
    showlegend=False,
    legendgroup='group2',
    hovertemplate='<b>Forecast</b>: %{y:.4f}<extra></extra>'
), row=1, col=2)

# Confidence interval
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_212.iloc[:, 1].values,
    fill=None,
    mode='lines',
    line=dict(color='lightgray', width=0.5, dash='dot'),
    showlegend=False,
    hoverinfo='skip'
), row=1, col=2)

fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_212.iloc[:, 0].values,
    fill='tonexty',
    mode='lines',
    line=dict(color='lightgray', width=0.5, dash='dot'),
    fillcolor='rgba(128,128,128,0.1)',
    showlegend=False,
    hoverinfo='skip'
), row=1, col=2)

# Update layout (Stock & Watson style)
fig.update_layout(
    title={
        'text': f'<b>ARIMA Model Comparison: Actual vs Forecasts</b><br>' +
                f'<sub>4-Quarter Ahead Forecast | Best Model: {best_model}</sub>',
        'y':0.96,
        'x':0.5,
        'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    height=450,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    font=dict(size=10, family='Times New Roman'),
    legend=dict(
        orientation='h',
        yanchor='bottom',
        y=1.02,
        xanchor='center',
        x=0.25,
        bgcolor='rgba(255,255,255,0.8)'
    ),
    margin=dict(l=60, r=40, t=110, b=60)
)

# Update axes (Stock & Watson style)
fig.update_xaxes(
    title_text="Time Period",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.update_yaxes(
    title_text="log(GDP)",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.10,
    xanchor='right', yanchor='top',
    font=dict(size=10, color='gray'),
    showarrow=False
)

fig.show()

# ============================================
# FORECAST DETAILS
# ============================================

print("\n" + "=" * 80)
print("FORECAST COMPARISON - 4 QUARTERS AHEAD")
print("=" * 80)

forecast_comparison = pd.DataFrame({
    'Quarter': [f'Q+{i}' for i in range(1, 5)],
    'Actual': test_data.values,
    'ARIMA(1,1,1)': forecast_values_111.values,
    'Error(1,1,1)': test_data.values - forecast_values_111.values,
    'ARIMA(2,1,2)': forecast_values_212.values,
    'Error(2,1,2)': test_data.values - forecast_values_212.values
})

print(forecast_comparison.to_string(index=False))
print("=" * 80)

print("\n✓ ARIMA Model Comparison Complete!")
```

The RMSE value for ARIMA (1,1,1) model is 0.0126 which is quite low comparitevly ARIMA(2,1,2) and indicates a good fit of the model to the data. A lower RMSE value suggests that the model's predictions are close to the actual observed values, making it a reliable choice for forecasting Pakistan's GDP based on the loggdp series.

## **Univariate Analysis of Interest_rate**

```{python}
import plotly.graph_objects as go

fig = go.Figure()

fig.add_trace(go.Scatter(
    x=df.index,
    y=df['interest_rate'],
    mode='lines',
    line=dict(color='#9b59b6', width=3),
    fill='tozeroy',
    fillcolor='rgba(155, 89, 182, 0.2)',
    hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br><b>Interest Rate</b>: %{y:.2f}%<br><extra></extra>'
))

fig.update_layout(
    title='<b>Pakistan Quarterly Interest Rate</b><br><sub>Trend Over Time</sub>',
    xaxis=dict(title='<b>Time Period</b>', showgrid=True, gridcolor='rgba(200,200,200,0.3)'),
    yaxis=dict(title='<b>Interest Rate (%)</b>', showgrid=True, gridcolor='rgba(200,200,200,0.3)'),
    plot_bgcolor='white',
    paper_bgcolor='#f5f5f5',
    height=550,
    showlegend=False
)

fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper', x=1.0, y=-0.12,
    xanchor='right', font=dict(size=10, color='gray'), showarrow=False
)

fig.show()
```

The Interest Rate plot displays the fluctuations in Pakistan's interest rates over the specified period. The graph indicates periods of both increases and decreases, reflecting changes in monetary policy and economic conditions. Overall, the interest rates show a downward trend, suggesting efforts to stimulate economic growth through lower borrowing costs.

## **Interest Rate Decompositions**

```{python}
from statsmodels.tsa.seasonal import seasonal_decompose
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# Decomposition
decomposition = seasonal_decompose(df['interest_rate'].dropna(), model='additive', period=4)

df['ir_trend'] = decomposition.trend
df['ir_residual'] = decomposition.resid

# ============================================
# SIDE-BY-SIDE LAYOUT (STOCK & WATSON STYLE)
# ============================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=('Original Interest Rate', 'Trend Component', 
                    'Residual Component', ''),
    vertical_spacing=0.12,
    horizontal_spacing=0.12,
    row_heights=[0.5, 0.5],
    column_widths=[0.5, 0.5],
    specs=[[{}, {}], [{}, None]]  # Last cell empty
)

# TOP LEFT: Original
fig.add_trace(
    go.Scatter(
        x=df.index, 
        y=df['interest_rate'], 
        mode='lines',
        line=dict(color='black', width=2),
        name='Original',
        hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br><b>Interest Rate</b>: %{y:.2f}%<br><extra></extra>'
    ),
    row=1, col=1
)

# TOP RIGHT: Trend
fig.add_trace(
    go.Scatter(
        x=df.index, 
        y=df['ir_trend'], 
        mode='lines',
        line=dict(color='black', width=2),
        name='Trend',
        hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br><b>Trend</b>: %{y:.2f}%<br><extra></extra>'
    ),
    row=1, col=2
)

# BOTTOM LEFT: Residual
fig.add_trace(
    go.Scatter(
        x=df.index, 
        y=df['ir_residual'], 
        mode='lines',
        line=dict(color='black', width=2),
        name='Residual',
        hovertemplate='<b>Quarter</b>: %{x|%Y-Q%q}<br><b>Residual</b>: %{y:.2f}%<br><extra></extra>'
    ),
    row=2, col=1
)

# Add zero line for residual
fig.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=2, col=1)

# Update layout (Stock & Watson style)
fig.update_layout(
    title={
        'text': '<b>Interest Rate Decomposition Analysis</b><br>' +
                '<sub>Original, Trend, and Residual Components</sub>',
        'y':0.96,
        'x':0.5,
        'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False,
    height=600,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

# Update axes (Stock & Watson style)
fig.update_xaxes(
    title_text="Time Period",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.update_yaxes(
    title_text="Interest Rate (%)",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

# Specific y-axis title for residual
fig.update_yaxes(title_text="Residual (%)", row=2, col=1)

fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.08,
    xanchor='right', yanchor='top',
    font=dict(size=10, color='gray'),
    showarrow=False
)

fig.show()
```

The graph decomposes the interest rate data from 2010 to 2020 into three components: the original interest rate, trend, and residual. The original interest rate shows fluctuations over time, with peaks and troughs. The trend component reveals a downward trend, indicating a general decrease in interest rates. The residual component captures short-term fluctuations and irregularities around the main trend.

## **ACF and PACF Analysis for Interest_rate for AR Process on level and first difference**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf

# ============================================
# CALCULATE FIRST DIFFERENCE
# ============================================

df['interest_rate_diff'] = df['interest_rate'].diff()

# Calculate ACF and PACF for both level and difference
acf_level = acf(df['interest_rate'].dropna(), nlags=20)
pacf_level = pacf(df['interest_rate'].dropna(), nlags=20)
confidence_level = 1.96 / np.sqrt(len(df['interest_rate'].dropna()))

acf_diff = acf(df['interest_rate_diff'].dropna(), nlags=20)
pacf_diff = pacf(df['interest_rate_diff'].dropna(), nlags=20)
confidence_diff = 1.96 / np.sqrt(len(df['interest_rate_diff'].dropna()))

lags = list(range(len(acf_level)))
lags_diff = list(range(len(acf_diff)))

# ============================================
# 1. LEVEL DATA - AR PROCESS (SIDE-BY-SIDE)
# ============================================

fig1 = make_subplots(
    rows=1, cols=2,
    subplot_titles=('ACF - Level Data', 'PACF - Level Data (AR Order)'),
    horizontal_spacing=0.12,
    column_widths=[0.5, 0.5]
)

# LEFT: ACF
fig1.add_trace(go.Bar(
    x=lags, y=acf_level, marker_color='black',
    hovertemplate='<b>Lag</b>: %{x}<br><b>ACF</b>: %{y:.4f}<br><extra></extra>'),
    row=1, col=1
)
fig1.add_hline(y=confidence_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig1.add_hline(y=-confidence_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig1.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=1)

# RIGHT: PACF
fig1.add_trace(go.Bar(
    x=lags, y=pacf_level, marker_color='black',
    hovertemplate='<b>Lag</b>: %{x}<br><b>PACF</b>: %{y:.4f}<br><extra></extra>'),
    row=1, col=2
)
fig1.add_hline(y=confidence_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig1.add_hline(y=-confidence_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig1.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=2)

fig1.update_layout(
    title={
        'text': '<b>AR Process - Level Data (Interest Rate)</b><br><sub>Use PACF for AR Order Identification</sub>',
        'y':0.96, 'x':0.5, 'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False, height=400, width=1200,
    plot_bgcolor='white', paper_bgcolor='white',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

fig1.update_xaxes(title_text="Lag", showgrid=False, showline=True, linewidth=1, 
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8))
fig1.update_yaxes(title_text="Autocorrelation", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8), range=[-1, 1], row=1, col=1)
fig1.update_yaxes(title_text="Partial Autocorrelation", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8), range=[-1, 1], row=1, col=2)

fig1.add_annotation(text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper', x=1.0, y=-0.12, xanchor='right',
    font=dict(size=10, color='gray'), showarrow=False)

fig1.show()

print("="*70)
print("AR PROCESS - LEVEL DATA")
print("="*70)
significant_pacf_level = [i for i in range(1, len(pacf_level)) if abs(pacf_level[i]) > confidence_level]
print(f"Significant PACF lags (AR order): {significant_pacf_level[:5]}")
print(f"Suggested AR(p): {len([i for i in significant_pacf_level if i <= 3])}")
print("="*70)

# ============================================
# 2. LEVEL DATA - MA PROCESS (SIDE-BY-SIDE)
# ============================================

fig2 = make_subplots(
    rows=1, cols=2,
    subplot_titles=('ACF - Level Data (MA Order)', 'PACF - Level Data'),
    horizontal_spacing=0.12,
    column_widths=[0.5, 0.5]
)

# LEFT: ACF
fig2.add_trace(go.Bar(
    x=lags, y=acf_level, marker_color='black',
    hovertemplate='<b>Lag</b>: %{x}<br><b>ACF</b>: %{y:.4f}<br><extra></extra>'),
    row=1, col=1
)
fig2.add_hline(y=confidence_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig2.add_hline(y=-confidence_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig2.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=1)

# RIGHT: PACF
fig2.add_trace(go.Bar(
    x=lags, y=pacf_level, marker_color='black',
    hovertemplate='<b>Lag</b>: %{x}<br><b>PACF</b>: %{y:.4f}<br><extra></extra>'),
    row=1, col=2
)
fig2.add_hline(y=confidence_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig2.add_hline(y=-confidence_level, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig2.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=2)

fig2.update_layout(
    title={
        'text': '<b>MA Process - Level Data (Interest Rate)</b><br><sub>Use ACF for MA Order Identification</sub>',
        'y':0.96, 'x':0.5, 'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False, height=400, width=1200,
    plot_bgcolor='white', paper_bgcolor='white',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

fig2.update_xaxes(title_text="Lag", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8))
fig2.update_yaxes(title_text="Autocorrelation", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8), range=[-1, 1], row=1, col=1)
fig2.update_yaxes(title_text="Partial Autocorrelation", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8), range=[-1, 1], row=1, col=2)

fig2.add_annotation(text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper', x=1.0, y=-0.12, xanchor='right',
    font=dict(size=10, color='gray'), showarrow=False)

fig2.show()

print("\n" + "="*70)
print("MA PROCESS - LEVEL DATA")
print("="*70)
significant_acf_level = [i for i in range(1, len(acf_level)) if abs(acf_level[i]) > confidence_level]
print(f"Significant ACF lags (MA order): {significant_acf_level[:5]}")
print(f"Suggested MA(q): {len([i for i in significant_acf_level if i <= 3])}")
print("="*70)

# ============================================
# 3. FIRST DIFFERENCE - AR PROCESS (SIDE-BY-SIDE)
# ============================================

fig3 = make_subplots(
    rows=1, cols=2,
    subplot_titles=('ACF - First Difference', 'PACF - First Difference (AR Order)'),
    horizontal_spacing=0.12,
    column_widths=[0.5, 0.5]
)

# LEFT: ACF
fig3.add_trace(go.Bar(
    x=lags_diff, y=acf_diff, marker_color='black',
    hovertemplate='<b>Lag</b>: %{x}<br><b>ACF</b>: %{y:.4f}<br><extra></extra>'),
    row=1, col=1
)
fig3.add_hline(y=confidence_diff, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig3.add_hline(y=-confidence_diff, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig3.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=1)

# RIGHT: PACF
fig3.add_trace(go.Bar(
    x=lags_diff, y=pacf_diff, marker_color='black',
    hovertemplate='<b>Lag</b>: %{x}<br><b>PACF</b>: %{y:.4f}<br><extra></extra>'),
    row=1, col=2
)
fig3.add_hline(y=confidence_diff, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig3.add_hline(y=-confidence_diff, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig3.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=2)

fig3.update_layout(
    title={
        'text': '<b>AR Process - First Difference (Interest Rate)</b><br><sub>Use PACF for AR Order Identification</sub>',
        'y':0.96, 'x':0.5, 'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False, height=400, width=1200,
    plot_bgcolor='white', paper_bgcolor='white',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

fig3.update_xaxes(title_text="Lag", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8))
fig3.update_yaxes(title_text="Autocorrelation", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8), range=[-1, 1], row=1, col=1)
fig3.update_yaxes(title_text="Partial Autocorrelation", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8), range=[-1, 1], row=1, col=2)

fig3.add_annotation(text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper', x=1.0, y=-0.12, xanchor='right',
    font=dict(size=10, color='gray'), showarrow=False)

fig3.show()

print("\n" + "="*70)
print("AR PROCESS - FIRST DIFFERENCE")
print("="*70)
significant_pacf_diff = [i for i in range(1, len(pacf_diff)) if abs(pacf_diff[i]) > confidence_diff]
print(f"Significant PACF lags (AR order): {significant_pacf_diff[:5]}")
print(f"Suggested AR(p): {len([i for i in significant_pacf_diff if i <= 3])}")
print("="*70)

# ============================================
# 4. FIRST DIFFERENCE - MA PROCESS (SIDE-BY-SIDE)
# ============================================

fig4 = make_subplots(
    rows=1, cols=2,
    subplot_titles=('ACF - First Difference (MA Order)', 'PACF - First Difference'),
    horizontal_spacing=0.12,
    column_widths=[0.5, 0.5]
)

# LEFT: ACF
fig4.add_trace(go.Bar(
    x=lags_diff, y=acf_diff, marker_color='black',
    hovertemplate='<b>Lag</b>: %{x}<br><b>ACF</b>: %{y:.4f}<br><extra></extra>'),
    row=1, col=1
)
fig4.add_hline(y=confidence_diff, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig4.add_hline(y=-confidence_diff, line_dash="dot", line_color="gray", line_width=1, row=1, col=1)
fig4.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=1)

# RIGHT: PACF
fig4.add_trace(go.Bar(
    x=lags_diff, y=pacf_diff, marker_color='black',
    hovertemplate='<b>Lag</b>: %{x}<br><b>PACF</b>: %{y:.4f}<br><extra></extra>'),
    row=1, col=2
)
fig4.add_hline(y=confidence_diff, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig4.add_hline(y=-confidence_diff, line_dash="dot", line_color="gray", line_width=1, row=1, col=2)
fig4.add_hline(y=0, line_dash="solid", line_color="gray", line_width=0.5, row=1, col=2)

fig4.update_layout(
    title={
        'text': '<b>MA Process - First Difference (Interest Rate)</b><br><sub>Use ACF for MA Order Identification</sub>',
        'y':0.96, 'x':0.5, 'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    showlegend=False, height=400, width=1200,
    plot_bgcolor='white', paper_bgcolor='white',
    margin=dict(l=60, r=40, t=100, b=60),
    font=dict(size=10, family='Times New Roman')
)

fig4.update_xaxes(title_text="Lag", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8))
fig4.update_yaxes(title_text="Autocorrelation", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8), range=[-1, 1], row=1, col=1)
fig4.update_yaxes(title_text="Partial Autocorrelation", showgrid=False, showline=True, linewidth=1,
                  linecolor='black', mirror=True, ticks='outside', tickfont=dict(size=8), range=[-1, 1], row=1, col=2)

fig4.add_annotation(text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper', x=1.0, y=-0.12, xanchor='right',
    font=dict(size=10, color='gray'), showarrow=False)

fig4.show()

print("\n" + "="*70)
print("MA PROCESS - FIRST DIFFERENCE")
print("="*70)
significant_acf_diff = [i for i in range(1, len(acf_diff)) if abs(acf_diff[i]) > confidence_diff]
print(f"Significant ACF lags (MA order): {significant_acf_diff[:5]}")
print(f"Suggested MA(q): {len([i for i in significant_acf_diff if i <= 3])}")
print("="*70)
```

The ACF Plot is slowly decaying on level it indicates the current value is highly dependent on its past values and when we take first difference the ACF go to exponentioanlly to zero after lag three it indicate the series is stationary on first difference.

## **ADF and KPSS test for Interest_rate at level and first difference**

```{python}
import pandas as pd
from statsmodels.tsa.stattools import adfuller, kpss

def stationarity_table(series, name="interest_rate", alpha=0.05):
    series = series.dropna()
    variants = {
        "Level": series,
        "First difference": series.diff().dropna()
    }
    rows = []
    for variant, data in variants.items():
        for reg in ["c", "ct"]:  # constant, constant+trend
            reg_label = {"c": "const", "ct": "const+trend"}[reg]
            for lag in range(1, 5):  # lags 1..4
                adf_stat, adf_p, *_ = adfuller(
                    data,
                    maxlag=lag,
                    regression=reg,
                    autolag=None  # use fixed lag
                )
                kpss_stat, kpss_p, *_ = kpss(
                    data,
                    regression=reg,
                    nlags=lag      # use fixed lag
                )
                rows.append({
                    "series": name,
                    "data": variant,
                    "trend_spec": reg_label,
                    "lag": lag,
                    "adf_stat": adf_stat,
                    "adf_p": adf_p,
                    "adf_flag": "✓" if adf_p < alpha else "x",       # ADF null: unit root
                    "kpss_stat": kpss_stat,
                    "kpss_p": kpss_p,
                    "kpss_flag": "✓" if kpss_p >= alpha else "x"     # KPSS null: stationarity
                })
    out = pd.DataFrame(rows)
    cols = [
        "series", "data", "trend_spec", "lag",
        "adf_stat", "adf_p", "adf_flag",
        "kpss_stat", "kpss_p", "kpss_flag"
    ]
    return out[cols]

table = stationarity_table(df["interest_rate"])
print(table.round({"adf_stat": 4, "adf_p": 4, "kpss_stat": 4, "kpss_p": 4}).to_string(index=False))
```

The interest rate is stationary at level as confirmed by ADF test with drift and 4 lags the p-value is 0.012 which is less than 5% significance level so we reject the null hypothesis and conclude that the series is stationary at level.

## **ARIMA (3,0,3) and ARIMA (2,1,2) model for Interest_rate series and**

```{python}
from statsmodels.tsa.arima.model import ARIMA
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# ============================================
# PREPARE DATA
# ============================================

data = df['interest_rate'].dropna()

# Split data: train (all but last 4) and test (last 4 for validation)
train_data = data[:-4]
test_data = data[-4:]

print("=" * 80)
print("ARIMA MODEL COMPARISON FOR INTEREST RATE")
print("=" * 80)
print(f"Total observations: {len(data)}")
print(f"Training observations: {len(train_data)}")
print(f"Test observations: {len(test_data)}")
print("=" * 80)

# ============================================
# FIT ARIMA(3,0,3) MODEL
# ============================================

print("\n" + "=" * 80)
print("FITTING ARIMA(3,0,3) MODEL")
print("=" * 80)

model_303 = ARIMA(train_data, order=(3, 0, 3))
results_303 = model_303.fit()

# Forecast 4 quarters ahead
forecast_303 = results_303.get_forecast(steps=4)
forecast_values_303 = forecast_303.predicted_mean
forecast_ci_303 = forecast_303.conf_int(alpha=0.05)

# Calculate RMSE
rmse_303 = np.sqrt(mean_squared_error(test_data, forecast_values_303))

print(f"\nAIC: {results_303.aic:.4f}")
print(f"BIC: {results_303.bic:.4f}")
print(f"RMSE (Root Mean Squared Error): {rmse_303:.6f}")

# ============================================
# FIT ARIMA(2,1,2) MODEL
# ============================================

print("\n" + "=" * 80)
print("FITTING ARIMA(2,1,2) MODEL")
print("=" * 80)

model_212 = ARIMA(train_data, order=(2, 1, 2))
results_212 = model_212.fit()

# Forecast 4 quarters ahead
forecast_212 = results_212.get_forecast(steps=4)
forecast_values_212 = forecast_212.predicted_mean
forecast_ci_212 = forecast_212.conf_int(alpha=0.05)

# Calculate RMSE
rmse_212 = np.sqrt(mean_squared_error(test_data, forecast_values_212))

print(f"\nAIC: {results_212.aic:.4f}")
print(f"BIC: {results_212.bic:.4f}")
print(f"RMSE (Root Mean Squared Error): {rmse_212:.6f}")

# ============================================
# MODEL COMPARISON TABLE
# ============================================

print("\n" + "=" * 80)
print("MODEL COMPARISON")
print("=" * 80)
comparison_df = pd.DataFrame({
    'Model': ['ARIMA(3,0,3)', 'ARIMA(2,1,2)'],
    'AIC': [results_303.aic, results_212.aic],
    'BIC': [results_303.bic, results_212.bic],
    'RMSE': [rmse_303, rmse_212]
})
print(comparison_df.to_string(index=False))
print("=" * 80)

# Determine best model
best_model = 'ARIMA(3,0,3)' if rmse_303 < rmse_212 else 'ARIMA(2,1,2)'
print(f"\n✓ Best Model (based on RMSE): {best_model}")
print("=" * 80)

# ============================================
# SIDE-BY-SIDE VISUALIZATION (STOCK & WATSON STYLE)
# ============================================

fig = make_subplots(
    rows=1, cols=2,
    subplot_titles=(f'ARIMA(3,0,3) | RMSE: {rmse_303:.4f}', 
                    f'ARIMA(2,1,2) | RMSE: {rmse_212:.4f}'),
    horizontal_spacing=0.10,
    column_widths=[0.5, 0.5]
)

# ============================================
# LEFT: ARIMA(3,0,3)
# ============================================

# Training data
fig.add_trace(go.Scatter(
    x=train_data.index.astype(str),
    y=train_data.values,
    mode='lines',
    name='Training',
    line=dict(color='black', width=1.5),
    showlegend=True,
    legendgroup='group1',
    hovertemplate='<b>Train</b>: %{y:.4f}<extra></extra>'
), row=1, col=1)

# Actual test data
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=test_data.values,
    mode='lines+markers',
    name='Actual',
    line=dict(color='black', width=2),
    marker=dict(size=6, color='black'),
    showlegend=True,
    legendgroup='group1',
    hovertemplate='<b>Actual</b>: %{y:.4f}<extra></extra>'
), row=1, col=1)

# Forecast
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_values_303.values,
    mode='lines+markers',
    name='Forecast (3,0,3)',
    line=dict(color='gray', width=1.5, dash='dash'),
    marker=dict(size=6, color='gray', symbol='x'),
    showlegend=True,
    legendgroup='group1',
    hovertemplate='<b>Forecast</b>: %{y:.4f}<extra></extra>'
), row=1, col=1)

# Confidence interval
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_303.iloc[:, 1].values,
    fill=None,
    mode='lines',
    line=dict(color='lightgray', width=0.5, dash='dot'),
    showlegend=False,
    hoverinfo='skip'
), row=1, col=1)

fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_303.iloc[:, 0].values,
    fill='tonexty',
    mode='lines',
    line=dict(color='lightgray', width=0.5, dash='dot'),
    fillcolor='rgba(128,128,128,0.1)',
    showlegend=False,
    hoverinfo='skip'
), row=1, col=1)

# ============================================
# RIGHT: ARIMA(2,1,2)
# ============================================

# Training data
fig.add_trace(go.Scatter(
    x=train_data.index.astype(str),
    y=train_data.values,
    mode='lines',
    name='Training',
    line=dict(color='black', width=1.5),
    showlegend=False,
    legendgroup='group2',
    hovertemplate='<b>Train</b>: %{y:.4f}<extra></extra>'
), row=1, col=2)

# Actual test data
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=test_data.values,
    mode='lines+markers',
    name='Actual',
    line=dict(color='black', width=2),
    marker=dict(size=6, color='black'),
    showlegend=False,
    legendgroup='group2',
    hovertemplate='<b>Actual</b>: %{y:.4f}<extra></extra>'
), row=1, col=2)

# Forecast
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_values_212.values,
    mode='lines+markers',
    name='Forecast (2,1,2)',
    line=dict(color='gray', width=1.5, dash='dash'),
    marker=dict(size=6, color='gray', symbol='diamond'),
    showlegend=False,
    legendgroup='group2',
    hovertemplate='<b>Forecast</b>: %{y:.4f}<extra></extra>'
), row=1, col=2)

# Confidence interval
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_212.iloc[:, 1].values,
    fill=None,
    mode='lines',
    line=dict(color='lightgray', width=0.5, dash='dot'),
    showlegend=False,
    hoverinfo='skip'
), row=1, col=2)

fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_212.iloc[:, 0].values,
    fill='tonexty',
    mode='lines',
    line=dict(color='lightgray', width=0.5, dash='dot'),
    fillcolor='rgba(128,128,128,0.1)',
    showlegend=False,
    hoverinfo='skip'
), row=1, col=2)

# Update layout (Stock & Watson style)
fig.update_layout(
    title={
        'text': f'<b>ARIMA Model Comparison: Interest Rate Forecasts</b><br>' +
                f'<sub>4-Quarter Ahead Forecast | Best Model: {best_model}</sub>',
        'y':0.96,
        'x':0.5,
        'xanchor': 'center',
        'font': dict(size=18, color='black', family='Times New Roman')
    },
    height=450,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    font=dict(size=10, family='Times New Roman'),
    legend=dict(
        orientation='h',
        yanchor='bottom',
        y=1.02,
        xanchor='center',
        x=0.25,
        bgcolor='rgba(255,255,255,0.8)'
    ),
    margin=dict(l=60, r=40, t=110, b=60)
)

# Update axes (Stock & Watson style)
fig.update_xaxes(
    title_text="Time Period",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.update_yaxes(
    title_text="Interest Rate (%)",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper', yref='paper',
    x=1.0, y=-0.10,
    xanchor='right', yanchor='top',
    font=dict(size=10, color='gray'),
    showarrow=False
)

fig.show()

# ============================================
# FORECAST DETAILS
# ============================================

print("\n" + "=" * 80)
print("FORECAST COMPARISON - 4 QUARTERS AHEAD")
print("=" * 80)

forecast_comparison = pd.DataFrame({
    'Quarter': [f'Q+{i}' for i in range(1, 5)],
    'Actual': test_data.values,
    'ARIMA(3,0,3)': forecast_values_303.values,
    'Error(3,0,3)': test_data.values - forecast_values_303.values,
    'ARIMA(2,1,2)': forecast_values_212.values,
    'Error(2,1,2)': test_data.values - forecast_values_212.values
})

print(forecast_comparison.to_string(index=False))
print("=" * 80)

print("\n✓ ARIMA Model Comparison Complete!")
```

The ARIMA (3,0,3) model for Interest_rate series has been selected based on its performance metrics. The RMSE value for this model is 0.0523, which indicates a reasonable fit to the data. This suggests that the model is effective in capturing the underlying patterns in Pakistan's interest rate data, making it suitable for forecasting future interest rate movements.

## **CPI_Quarterly_Avg univariate Analysis**

```{python}
import plotly.graph_objects as go
import pandas as pd
import numpy as np

# ==========================================
# TIME PLOT FOR CPI (Quarterly Average)
# ==========================================

fig = go.Figure()

# Add CPI line with shaded area
fig.add_trace(go.Scatter(
    x=df.index, 
    y=df['CPI_Quarterly_Avg'],
    mode='lines+markers',
    name='CPI',
    line=dict(color='#1e88e5', width=3),
    marker=dict(size=5, color='#1e88e5'),
    fill='tozeroy',
    fillcolor='rgba(30, 136, 229, 0.12)',
    hovertemplate='<b>%{x}</b><br>CPI: %{y:.2f}<extra></extra>'
))

# Layout
fig.update_layout(
    title={
        'text': '<b>Consumer Price Index (CPI) - Quarterly Average</b><br>' +
                '<sub>Pakistan (2010-2020)</sub>',
        'x': 0.5,
        'xanchor': 'center',
        'font': {'size': 24, 'color': '#1a1a1a', 'family': 'Arial Black'}
    },
    xaxis={
        'title': '<b>Quarter</b>',
        'showgrid': True,
        'gridcolor': 'rgba(200,200,200,0.3)',
        'showline': True,
        'linewidth': 2,
        'linecolor': '#333',
        'tickfont': {'size': 12},
        'rangeslider': {'visible': False}
    },
    yaxis={
        'title': '<b>CPI Value</b>',
        'showgrid': True,
        'gridcolor': 'rgba(200,200,200,0.3)',
        'showline': True,
        'linewidth': 2,
        'linecolor': '#333',
        'tickfont': {'size': 12}
    },
    plot_bgcolor='white',
    paper_bgcolor='#fafafa',
    height=600,
    hovermode='x unified',
    showlegend=False,
    margin=dict(l=80, r=60, t=120, b=100),
    annotations=[
        {
            'text': '<i>Source: Pakistan Bureau of Statistics</i>',
            'xref': 'paper',
            'yref': 'paper',
            'x': 1.0,
            'y': -0.13,
            'xanchor': 'right',
            'showarrow': False,
            'font': {'size': 11, 'color': '#666'}
        }
    ]
)

fig.show()
```

The time series plot of CPI_Quarterly_Avg shows the trend of Pakistan's Consumer Price Index (CPI) over time. The graph indicates a general upward trend, reflecting increasing prices and inflationary pressures in the economy. There are also noticeable fluctuations that may correspond to economic events or policy changes affecting consumer prices.

## **CPI Decompositions**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.tsa.seasonal import seasonal_decompose

# Decompose (seasonal removed from plots)
ts_cpi = df['CPI_Quarterly_Avg'].dropna()
decomposition_model = 'additive' if (ts_cpi <= 0).any() else 'multiplicative'
decomposition = seasonal_decompose(ts_cpi, model=decomposition_model, period=4)

decomp_df = pd.DataFrame({
    'Original': ts_cpi,
    'Trend': decomposition.trend,
    'Residual': decomposition.resid
})

# Simple rolling band for dashed lines
band = decomp_df['Residual'].rolling(4, min_periods=1).std()

fig = make_subplots(
    rows=1, cols=3, shared_xaxes=False, shared_yaxes=False,
    horizontal_spacing=0.05,
    subplot_titles=('Original CPI Series', 'Trend Component', 'Residual Component')
)

def add_panel(col_name, col_idx):
    series = decomp_df[col_name]
    upper = series + band
    lower = series - band

    fig.add_trace(
        go.Scatter(x=series.index, y=upper, mode='lines',
                   line=dict(color='gray', width=1, dash='dash'),
                   showlegend=False),
        row=1, col=col_idx
    )
    fig.add_trace(
        go.Scatter(x=series.index, y=lower, mode='lines',
                   line=dict(color='gray', width=1, dash='dash'),
                   showlegend=False),
        row=1, col=col_idx
    )
    fig.add_trace(
        go.Scatter(x=series.index, y=series, mode='lines',
                   line=dict(color='black', width=3),
                   showlegend=False),
        row=1, col=col_idx
    )

    # Blue frame around each subplot (use x/x2/x3 and y/y2/y3 domains)
    axis_suffix = '' if col_idx == 1 else col_idx
    fig.add_shape(
        type="rect",
        xref=f"x{axis_suffix} domain",
        yref=f"y{axis_suffix} domain",
        x0=0, x1=1, y0=0, y1=1,
        line=dict(color='blue', width=4),
        row=1, col=col_idx
    )

add_panel('Original', 1)
add_panel('Trend', 2)
add_panel('Residual', 3)

fig.update_yaxes(title_text="Percent", showgrid=False)
fig.update_xaxes(showgrid=False)

fig.update_layout(
    title_text='<b>CPI Decomposition (Seasonal Removed)</b>',
    title_x=0.5,
    height=220, width=1200,
    template="none",
    margin=dict(l=20, r=20, t=50, b=20),
    hovermode='x unified',
    showlegend=False,
    plot_bgcolor="white",
    paper_bgcolor="white",
    font=dict(color='black', size=12)
)

fig.show()
```

The graph decomposes the Consumer Price Index (CPI) data from 2010 to 2020 into three components: the original CPI series, trend component, and residual component. The original CPI shows a steady increase. The trend component displays a smooth upward trajectory, reflecting long-term inflation growth. The residual component captures the short-term fluctuations and irregularities after removing seasonal effects.

## **ACF and PACF Analysis of AR Process for CPI_Quarterly_Avg**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf

# ==========================================
# ACF AND PACF ANALYSIS FOR CPI
# ==========================================

# Prepare data
cpi_data = df['CPI_Quarterly_Avg'].dropna()
cpi_diff = cpi_data.diff().dropna()

# Calculate ACF and PACF
acf_level = acf(cpi_data, nlags=20, alpha=0.05)
pacf_level = pacf(cpi_data, nlags=20, alpha=0.05)
acf_diff = acf(cpi_diff, nlags=20, alpha=0.05)
pacf_diff = pacf(cpi_diff, nlags=20, alpha=0.05)

# Confidence intervals
ci_level = 1.96 / np.sqrt(len(cpi_data))
ci_diff = 1.96 / np.sqrt(len(cpi_diff))

# ==========================================
# COMPACT 2x2 LAYOUT: ALL ACF/PACF PLOTS
# ==========================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        '<b>ACF - CPI at Level</b>', 
        '<b>PACF - CPI at Level</b>',
        '<b>ACF - First Difference</b>', 
        '<b>PACF - First Difference</b>'
    ),
    horizontal_spacing=0.12,
    vertical_spacing=0.15
)

# --- Row 1, Col 1: ACF at Level ---
lags_range = range(len(acf_level[0]))
fig.add_trace(go.Bar(
    x=list(lags_range),
    y=acf_level[0],
    marker_color='#1e88e5',
    name='ACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=1, col=1)

fig.add_hline(y=ci_level, line_dash="dash", line_color="red", 
               line_width=1.5, row=1, col=1)
fig.add_hline(y=-ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=1)

# --- Row 1, Col 2: PACF at Level ---
fig.add_trace(go.Bar(
    x=list(lags_range),
    y=pacf_level[0],
    marker_color='#43a047',
    name='PACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=1, col=2)

fig.add_hline(y=ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=-ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=2)

# --- Row 2, Col 1: ACF at First Difference ---
lags_range_diff = range(len(acf_diff[0]))
fig.add_trace(go.Bar(
    x=list(lags_range_diff),
    y=acf_diff[0],
    marker_color='#1e88e5',
    name='ACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=2, col=1)

fig.add_hline(y=ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=-ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=1)

# --- Row 2, Col 2: PACF at First Difference ---
fig.add_trace(go.Bar(
    x=list(lags_range_diff),
    y=pacf_diff[0],
    marker_color='#43a047',
    name='PACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=2, col=2)

fig.add_hline(y=ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=-ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=2)

# --- Update Layout ---
fig.update_layout(
    title={
        'text': '<b>ACF and PACF Analysis - CPI (Level & First Difference)</b><br>' +
                '<sub>Consumer Price Index | Pakistan (2010-2020)</sub>',
        'x': 0.5,
        'xanchor': 'center',
        'font': {'size': 20, 'color': '#1a1a1a', 'family': 'Arial Black'}
    },
    height=700,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='#fafafa',
    margin=dict(l=60, r=60, t=120, b=80),
    showlegend=False
)

# Update all axes
fig.update_xaxes(title_text="<b>Lag</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})
fig.update_yaxes(title_text="<b>Correlation</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})

# Add source annotation
fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.08,
    xanchor='center',
    showarrow=False,
    font={'size': 11, 'color': '#666'}
)

fig.show()
```

The ACF go to zero after 9 lag and PACF cuts off after lag 2 it confuse whether the series is stationary or not on first difference we confirm through ADF and KPSS test the stationarity of data.

## **MA Process for CPI_Quarterly_Avg**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf

# ==========================================
# ACF AND PACF ANALYSIS FOR CPI - MA PROCESS
# ==========================================

# Prepare data
cpi_data = df['CPI_Quarterly_Avg'].dropna()
cpi_diff = cpi_data.diff().dropna()

# Calculate ACF and PACF
acf_level = acf(cpi_data, nlags=20, alpha=0.05)
pacf_level = pacf(cpi_data, nlags=20, alpha=0.05)
acf_diff = acf(cpi_diff, nlags=20, alpha=0.05)
pacf_diff = pacf(cpi_diff, nlags=20, alpha=0.05)

# Confidence intervals
ci_level = 1.96 / np.sqrt(len(cpi_data))
ci_diff = 1.96 / np.sqrt(len(cpi_diff))

# ==========================================
# COMPACT 2x2 LAYOUT: MA PROCESS ANALYSIS
# ==========================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        '<b>ACF - Level (cuts off at lag q)</b>', 
        '<b>PACF - Level (decays gradually)</b>',
        '<b>ACF - First Diff (cuts off at lag q)</b>', 
        '<b>PACF - First Diff (decays gradually)</b>'
    ),
    horizontal_spacing=0.12,
    vertical_spacing=0.15
)

# --- Row 1, Col 1: ACF at Level ---
lags_range = range(len(acf_level[0]))
fig.add_trace(go.Bar(
    x=list(lags_range),
    y=acf_level[0],
    marker_color='#e91e63',
    name='ACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=1, col=1)

fig.add_hline(y=ci_level, line_dash="dash", line_color="red", 
               line_width=1.5, row=1, col=1)
fig.add_hline(y=-ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=1)

# --- Row 1, Col 2: PACF at Level ---
fig.add_trace(go.Bar(
    x=list(lags_range),
    y=pacf_level[0],
    marker_color='#ff9800',
    name='PACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=1, col=2)

fig.add_hline(y=ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=-ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=2)

# --- Row 2, Col 1: ACF at First Difference ---
lags_range_diff = range(len(acf_diff[0]))
fig.add_trace(go.Bar(
    x=list(lags_range_diff),
    y=acf_diff[0],
    marker_color='#e91e63',
    name='ACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=2, col=1)

fig.add_hline(y=ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=-ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=1)

# --- Row 2, Col 2: PACF at First Difference ---
fig.add_trace(go.Bar(
    x=list(lags_range_diff),
    y=pacf_diff[0],
    marker_color='#ff9800',
    name='PACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=2, col=2)

fig.add_hline(y=ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=-ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=2)

# --- Update Layout ---
fig.update_layout(
    title={
        'text': '<b>MA Process Analysis - CPI (Level & First Difference)</b><br>' +
                '<sub>ACF cuts off after lag q | PACF decays gradually | Pakistan (2010-2020)</sub>',
        'x': 0.5,
        'xanchor': 'center',
        'font': {'size': 20, 'color': '#1a1a1a', 'family': 'Arial Black'}
    },
    height=700,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='#fafafa',
    margin=dict(l=60, r=60, t=120, b=80),
    showlegend=False
)

# Update all axes
fig.update_xaxes(title_text="<b>Lag</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})
fig.update_yaxes(title_text="<b>Correlation</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})

# Add source annotation
fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.08,
    xanchor='center',
    showarrow=False,
    font={'size': 11, 'color': '#666'}
)

fig.show()
```

MA process for CPI_Quarterly_Avg shows that ACF cuts off after lag 9 and PACF go to zero exponentially it indicate the series is stationary on first difference. Now we check through formal test.

**ADF and KPSS tests for CPI_Quarterly_Avg**

```{python}
import pandas as pd
from statsmodels.tsa.stattools import adfuller, kpss

def stationarity_table(series, name="CPI_Quarterly_Avg", alpha=0.05):
    series = series.dropna()
    variants = {
        "Level": series,
        "First difference": series.diff().dropna()
    }
    rows = []
    for variant, data in variants.items():
        for reg in ["c", "ct"]:  # constant; constant+trend
            reg_label = {"c": "const", "ct": "const+trend"}[reg]
            adf_stat, adf_p, *_ = adfuller(
                data,
                maxlag=4,
                regression=reg,
                autolag=None  # fixed lag = 4
            )
            kpss_stat, kpss_p, *_ = kpss(
                data,
                regression=reg,
                nlags=4       # fixed lag = 4
            )
            rows.append({
                "series": name,
                "data": variant,
                "trend_spec": reg_label,
                "lag": 4,
                "adf_stat": adf_stat,
                "adf_p": adf_p,
                "adf_flag": "✓" if adf_p < alpha else "x",       # ADF null: unit root
                "kpss_stat": kpss_stat,
                "kpss_p": kpss_p,
                "kpss_flag": "✓" if kpss_p >= alpha else "x"     # KPSS null: stationarity
            })
    cols = [
        "series", "data", "trend_spec", "lag",
        "adf_stat", "adf_p", "adf_flag",
        "kpss_stat", "kpss_p", "kpss_flag"
    ]
    return pd.DataFrame(rows)[cols]

table = stationarity_table(df["CPI_Quarterly_Avg"])
print(table.round({"adf_stat": 4, "adf_p": 4, "kpss_stat": 4, "kpss_p": 4}).to_string(index=False))
```

The CPI_Quarterly_AVG series is stationary on first difference as confirmed by KPSS with drift and 4 lags as we have seen the P-value of KPSS test is greater than 0.05 we fail to reject the null hypothesis and conclude that the series is stationary on first difference.

**ARIMA (1,1,9) model for CPI_Quarterly_Avg series**

```{python}
from statsmodels.tsa.arima.model import ARIMA
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# ==========================================
# PREPARE DATA
# ==========================================

data = df['CPI_Quarterly_Avg'].dropna()

# Split data: train (all but last 4) and test (last 4 for validation)
train_data = data[:-4]
test_data = data[-4:]

print("=" * 80)
print("ARIMA MODEL COMPARISON FOR CPI_Quarterly_Avg")
print("=" * 80)
print(f"Total observations: {len(data)}")
print(f"Training observations: {len(train_data)}")
print(f"Test observations: {len(test_data)}")
print("=" * 80)

# ==========================================
# FIT ARIMA(1,1,9) MODEL
# ==========================================

print("\n" + "=" * 80)
print("FITTING ARIMA(1,1,9) MODEL")
print("=" * 80)

model_119 = ARIMA(train_data, order=(1, 1, 9))
results_119 = model_119.fit()

# Forecast 4 quarters ahead
forecast_119 = results_119.get_forecast(steps=4)
forecast_values_119 = forecast_119.predicted_mean
forecast_ci_119 = forecast_119.conf_int(alpha=0.05)

# Calculate RMSE
rmse_119 = np.sqrt(mean_squared_error(test_data, forecast_values_119))

print(f"\nAIC: {results_119.aic:.4f}")
print(f"BIC: {results_119.bic:.4f}")
print(f"RMSE (Root Mean Squared Error): {rmse_119:.6f}")

# ==========================================
# FIT ARIMA(2,1,9) MODEL
# ==========================================

print("\n" + "=" * 80)
print("FITTING ARIMA(2,1,9) MODEL")
print("=" * 80)

model_219 = ARIMA(train_data, order=(2, 1, 9))
results_219 = model_219.fit()

# Forecast 4 quarters ahead
forecast_219 = results_219.get_forecast(steps=4)
forecast_values_219 = forecast_219.predicted_mean
forecast_ci_219 = forecast_219.conf_int(alpha=0.05)

# Calculate RMSE
rmse_219 = np.sqrt(mean_squared_error(test_data, forecast_values_219))

print(f"\nAIC: {results_219.aic:.4f}")
print(f"BIC: {results_219.bic:.4f}")
print(f"RMSE (Root Mean Squared Error): {rmse_219:.6f}")

# ==========================================
# MODEL COMPARISON TABLE
# ==========================================

print("\n" + "=" * 80)
print("MODEL COMPARISON")
print("=" * 80)
comparison_df = pd.DataFrame({
    'Model': ['ARIMA(1,1,9)', 'ARIMA(2,1,9)'],
    'AIC': [results_119.aic, results_219.aic],
    'BIC': [results_119.bic, results_219.bic],
    'RMSE': [rmse_119, rmse_219]
})
print(comparison_df.to_string(index=False))
print("=" * 80)

# Determine best model
best_model = 'ARIMA(1,1,9)' if rmse_119 < rmse_219 else 'ARIMA(2,1,9)'
print(f"\n✓ Best Model (based on RMSE): {best_model}")
print("=" * 80)

# ==========================================
# COMPACT 1x2 VISUALIZATION: SIDE-BY-SIDE COMPARISON
# ==========================================

fig = make_subplots(
    rows=1, cols=2,
    subplot_titles=(
        f'<b>ARIMA(1,1,9) | RMSE: {rmse_119:.4f}</b>',
        f'<b>ARIMA(2,1,9) | RMSE: {rmse_219:.4f}</b>'
    ),
    horizontal_spacing=0.10
)

# ============ LEFT PLOT: ARIMA(1,1,9) ============

# Training data
fig.add_trace(go.Scatter(
    x=train_data.index.astype(str),
    y=train_data.values,
    mode='lines',
    name='Training',
    line=dict(color='#3498db', width=2),
    legendgroup='group1',
    showlegend=True,
    hovertemplate='<b>Training</b><br>%{x}: %{y:.4f}<extra></extra>'
), row=1, col=1)

# Actual test data
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=test_data.values,
    mode='lines+markers',
    name='Actual',
    line=dict(color='#2ecc71', width=2.5),
    marker=dict(size=7),
    legendgroup='group1',
    showlegend=True,
    hovertemplate='<b>Actual</b><br>%{x}: %{y:.4f}<extra></extra>'
), row=1, col=1)

# ARIMA(1,1,9) Forecast
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_values_119.values,
    mode='lines+markers',
    name='Forecast (1,1,9)',
    line=dict(color='#e74c3c', width=2, dash='dash'),
    marker=dict(size=7, symbol='x'),
    legendgroup='group1',
    showlegend=True,
    hovertemplate='<b>Forecast</b><br>%{x}: %{y:.4f}<extra></extra>'
), row=1, col=1)

# Confidence interval for ARIMA(1,1,9)
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_119.iloc[:, 1].values,
    fill=None,
    mode='lines',
    line_color='rgba(0,0,0,0)',
    showlegend=False,
    hoverinfo='skip'
), row=1, col=1)

fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_119.iloc[:, 0].values,
    fill='tonexty',
    mode='lines',
    line_color='rgba(0,0,0,0)',
    name='95% CI',
    fillcolor='rgba(231, 76, 60, 0.2)',
    legendgroup='group1',
    showlegend=True,
    hovertemplate='<b>95% CI</b><extra></extra>'
), row=1, col=1)

# ============ RIGHT PLOT: ARIMA(2,1,9) ============

# Training data
fig.add_trace(go.Scatter(
    x=train_data.index.astype(str),
    y=train_data.values,
    mode='lines',
    name='Training',
    line=dict(color='#3498db', width=2),
    legendgroup='group2',
    showlegend=False,
    hovertemplate='<b>Training</b><br>%{x}: %{y:.4f}<extra></extra>'
), row=1, col=2)

# Actual test data
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=test_data.values,
    mode='lines+markers',
    name='Actual',
    line=dict(color='#2ecc71', width=2.5),
    marker=dict(size=7),
    legendgroup='group2',
    showlegend=False,
    hovertemplate='<b>Actual</b><br>%{x}: %{y:.4f}<extra></extra>'
), row=1, col=2)

# ARIMA(2,1,9) Forecast
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_values_219.values,
    mode='lines+markers',
    name='Forecast (2,1,9)',
    line=dict(color='#9b59b6', width=2, dash='dash'),
    marker=dict(size=7, symbol='x'),
    legendgroup='group2',
    showlegend=False,
    hovertemplate='<b>Forecast</b><br>%{x}: %{y:.4f}<extra></extra>'
), row=1, col=2)

# Confidence interval for ARIMA(2,1,9)
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_219.iloc[:, 1].values,
    fill=None,
    mode='lines',
    line_color='rgba(0,0,0,0)',
    showlegend=False,
    hoverinfo='skip'
), row=1, col=2)

fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_219.iloc[:, 0].values,
    fill='tonexty',
    mode='lines',
    line_color='rgba(0,0,0,0)',
    name='95% CI',
    fillcolor='rgba(155, 89, 182, 0.2)',
    legendgroup='group2',
    showlegend=False,
    hovertemplate='<b>95% CI</b><extra></extra>'
), row=1, col=2)

# ============ UPDATE LAYOUT ============

fig.update_layout(
    title={
        'text': f'<b>ARIMA Model Comparison: Actual vs Forecast</b><br>' +
                f'<sub>4-Quarter Forecast | Best Model: {best_model}</sub>',
        'y': 0.98,
        'x': 0.5,
        'xanchor': 'center',
        'font': dict(size=18, color='#1a1a1a', family='Arial Black')
    },
    height=550,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='#f5f5f5',
    hovermode='x unified',
    legend=dict(
        orientation='h',
        x=0.5,
        y=-0.15,
        xanchor='center',
        bgcolor='rgba(255,255,255,0.8)'
    ),
    margin=dict(l=60, r=60, t=100, b=100)
)

# Update axes
fig.update_xaxes(title_text="<b>Time Period</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 9})
fig.update_yaxes(title_text="<b>CPI Value</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})

# Add source annotation
fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.22,
    xanchor='center',
    showarrow=False,
    font=dict(size=10, color='#7f8c8d')
)

fig.show()

# ==========================================
# FORECAST DETAILS
# ==========================================

print("\n" + "=" * 80)
print("FORECAST COMPARISON - 4 QUARTERS AHEAD")
print("=" * 80)

forecast_comparison = pd.DataFrame({
    'Quarter': [f'Q+{i}' for i in range(1, 5)],
    'Actual': test_data.values,
    'ARIMA(1,1,9)': forecast_values_119.values,
    'Error(1,1,9)': test_data.values - forecast_values_119.values,
    'ARIMA(2,1,9)': forecast_values_219.values,
    'Error(2,1,9)': test_data.values - forecast_values_219.values
})

print(forecast_comparison.to_string(index=False))
print("=" * 80)

print("\n✓ ARIMA Model Comparison Complete!")
```

The ARIMA (1,1,9) model for CPI_Quarterly_Avg series has been selected based on its performance metrics. The RMSE value for this model is 1.8183 which is lower than ARIMA (2,1,9) RMSE 2.1229 which indicates a good fit to the data. This suggests that the model is effective in capturing the underlying patterns in Pakistan's Consumer Price Index data, making it suitable for forecasting future CPI movements.

**Univariate_Analysis of government_expenditure**

```{python}
import plotly.graph_objects as go

# assumes df has a DatetimeIndex or a 'date' column
ts = df.set_index('date') if 'date' in df.columns else df
y = ts['government_spending'].dropna()

fig = go.Figure()

fig.add_trace(go.Scatter(
    x=y.index, y=y,
    mode='lines+markers',
    name='Government Spending',
    line=dict(color='#1f77b4', width=2),
    marker=dict(size=6, color='#1f77b4', line=dict(color='white', width=1))
))

fig.update_layout(
    title={'text': 'Government Spending Over Time<br><span style="font-size:0.8em;">Pakistan Bureau of Statistics</span>',
           'x': 0.02, 'xanchor': 'left'},
    xaxis_title='Date',
    yaxis_title='Government Spending',
    plot_bgcolor='white',
    paper_bgcolor='white',
    hovermode='x unified',
    margin=dict(l=60, r=30, t=80, b=60),
    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
)

fig.update_xaxes(showgrid=True, gridcolor='#e6e6e6')
fig.update_yaxes(showgrid=True, gridcolor='#e6e6e6')

# Optional: add a faint smoothing line (lowess-like) if you have many points
# fig.add_trace(go.Scatter(x=y.index, y=y.rolling(4, min_periods=1).mean(),
#                          mode='lines', name='Rolling Mean (4)', line=dict(color='#ff7f0e', width=2, dash='dash')))

fig.show()
```

The government_expenditure plot illustrates the trend of Pakistan's government expenditure over time. The graph shows a general upward trend, indicating increasing government spending, which may reflect fiscal policies aimed at stimulating economic growth or addressing public needs. There are also fluctuations that could correspond to changes in government budgets or economic conditions.

**Time Series Decomposition of government_expenditure**

```{python}
import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# ==========================================
# PREP SERIES
# ==========================================
ts = df.copy()
if 'date' in ts.columns:
    ts['date'] = pd.to_datetime(ts['date'])
    ts = ts.set_index('date')
ts = ts.sort_index()

y = ts['government_spending']

# Force a datetime index
if not isinstance(y.index, pd.DatetimeIndex):
    raise ValueError("Need a datetime index or a 'date' column for government_spending.")

# Infer frequency; default to quarterly if unknown
freq = y.index.freqstr or y.index.inferred_freq or 'Q'
y = y.asfreq(freq)

# Fill gaps
y = y.interpolate(limit_direction='both').ffill().bfill()
y = y.dropna()

n = len(y)
if n < 4:
    raise ValueError(f"Not enough data to decompose (have {n} points).")

# Choose period based on freq, then shrink if too long for the data
period_lookup = {'M': 12, 'MS': 12, 'Q': 4, 'QS': 4}
period = period_lookup.get(freq, 4)
if n < 2 * period:  # minimal requirement ~2 seasons
    period = max(2, n // 2)

result = seasonal_decompose(y, model='additive', period=period, extrapolate_trend='freq')

# ==========================================
# COMPACT 2x2 LAYOUT (WITHOUT SEASONAL)
# ==========================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        '<b>Observed Series</b>',
        '<b>Trend Component</b>',
        '<b>Residual Component</b>',
        ''  # Empty placeholder for 4th position
    ),
    horizontal_spacing=0.12,
    vertical_spacing=0.15,
    specs=[
        [{"type": "scatter"}, {"type": "scatter"}],
        [{"type": "scatter"}, {"type": "scatter"}]
    ]
)

# --- Row 1, Col 1: Observed ---
fig.add_trace(
    go.Scatter(
        x=y.index,
        y=result.observed,
        mode='lines',
        name='Observed',
        line=dict(color='#2c3e50', width=2),
        showlegend=False,
        hovertemplate='<b>Date</b>: %{x}<br><b>Value</b>: %{y:.2f}<extra></extra>'
    ),
    row=1, col=1
)

# --- Row 1, Col 2: Trend ---
fig.add_trace(
    go.Scatter(
        x=y.index,
        y=result.trend,
        mode='lines',
        name='Trend',
        line=dict(color='#27ae60', width=2.5),
        showlegend=False,
        hovertemplate='<b>Date</b>: %{x}<br><b>Trend</b>: %{y:.2f}<extra></extra>'
    ),
    row=1, col=2
)

# --- Row 2, Col 1: Residual ---
fig.add_trace(
    go.Scatter(
        x=y.index,
        y=result.resid,
        mode='lines',
        name='Residual',
        line=dict(color='#e74c3c', width=2),
        showlegend=False,
        hovertemplate='<b>Date</b>: %{x}<br><b>Residual</b>: %{y:.2f}<extra></extra>'
    ),
    row=2, col=1
)

# Add zero line to residual plot
fig.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1, row=2, col=1)

# --- Row 2, Col 2: Leave empty or add a note ---
fig.add_annotation(
    text='<i>Seasonal component<br>excluded from analysis</i>',
    xref='x4', yref='y4',
    x=0.5, y=0.5,
    xanchor='center', yanchor='middle',
    showarrow=False,
    font=dict(size=14, color='#7f8c8d', family='Arial'),
    align='center'
)

# Hide the 4th subplot axes
fig.update_xaxes(visible=False, row=2, col=2)
fig.update_yaxes(visible=False, row=2, col=2)

# ==========================================
# UPDATE LAYOUT
# ==========================================

fig.update_layout(
    title={
        'text': '<b>Government Spending - Time Series Decomposition</b><br>' +
                '<sub>Observed, Trend & Residual Components (Seasonal Excluded)</sub>',
        'x': 0.5,
        'xanchor': 'center',
        'font': {'size': 20, 'color': '#1a1a1a', 'family': 'Arial Black'}
    },
    height=700,
    width=1200,
    showlegend=False,
    plot_bgcolor='white',
    paper_bgcolor='#fafafa',
    margin=dict(l=60, r=60, t=100, b=80)
)

# Update axes
fig.update_xaxes(title_text="<b>Date</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=2, col=1)
fig.update_xaxes(title_text="<b>Date</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=1, col=2)
fig.update_xaxes(title_text="<b>Date</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=1, col=1)

fig.update_yaxes(title_text="<b>Value</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=1, col=1)
fig.update_yaxes(title_text="<b>Trend</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=1, col=2)
fig.update_yaxes(title_text="<b>Residual</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=2, col=1)

# Add source annotation
fig.add_annotation(
    text='<b>Source: Pakistan Bureau of Statistics</b>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.08,
    xanchor='center',
    showarrow=False,
    font=dict(size=12, color='#2c3e50')
)

fig.show()
```

The time series decomposition of government_expenditure reveals the underlying components that contribute to the overall pattern of Pakistan's government spending over time. The trend component indicates a consistent increase in government expenditure, reflecting fiscal policies aimed at economic development and public welfare. The residual component represents irregular variations that are not explained by the trend or seasonal factors, indicating the presence of unexpected events or changes in fiscal policy. This decomposition provides valuable insights into the dynamics of government expenditure in Pakistan, aiding in better economic planning and analysis.

**ACF and PACf Analysis of AR Process for government_expenditure**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf

# ==========================================
# ACF AND PACF ANALYSIS FOR GOVERNMENT SPENDING - AR PROCESS
# ==========================================

# Prepare data
ts = df.copy()
if 'date' in ts.columns:
    ts['date'] = pd.to_datetime(ts['date'])
    ts = ts.set_index('date')
ts = ts.sort_index()

# Use government_spending column
govexp_data = ts['government_spending'].dropna()
govexp_diff = govexp_data.diff().dropna()

nlags = 20

# Calculate ACF and PACF
acf_level = acf(govexp_data, nlags=nlags, fft=False)
pacf_level = pacf(govexp_data, nlags=nlags, method="ywmle")
acf_diff = acf(govexp_diff, nlags=nlags, fft=False)
pacf_diff = pacf(govexp_diff, nlags=nlags, method="ywmle")

# Confidence intervals
ci_level = 1.96 / np.sqrt(len(govexp_data))
ci_diff = 1.96 / np.sqrt(len(govexp_diff))

# ==========================================
# COMPACT 2x2 LAYOUT: AR PROCESS ANALYSIS
# ==========================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        '<b>ACF - Level (decays gradually)</b>',
        '<b>PACF - Level (cuts off at lag p)</b>',
        '<b>ACF - First Diff (decays gradually)</b>',
        '<b>PACF - First Diff (cuts off at lag p)</b>'
    ),
    horizontal_spacing=0.12,
    vertical_spacing=0.15
)

# --- Row 1, Col 1: ACF at Level ---
lags_range = range(len(acf_level))
fig.add_trace(go.Bar(
    x=list(lags_range),
    y=acf_level,
    marker_color='#1e88e5',
    name='ACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=1, col=1)

fig.add_hline(y=ci_level, line_dash="dash", line_color="red", 
               line_width=1.5, row=1, col=1)
fig.add_hline(y=-ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=1)

# --- Row 1, Col 2: PACF at Level ---
fig.add_trace(go.Bar(
    x=list(lags_range),
    y=pacf_level,
    marker_color='#43a047',
    name='PACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=1, col=2)

fig.add_hline(y=ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=-ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=2)

# --- Row 2, Col 1: ACF at First Difference ---
lags_range_diff = range(len(acf_diff))
fig.add_trace(go.Bar(
    x=list(lags_range_diff),
    y=acf_diff,
    marker_color='#1e88e5',
    name='ACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=2, col=1)

fig.add_hline(y=ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=-ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=1)

# --- Row 2, Col 2: PACF at First Difference ---
fig.add_trace(go.Bar(
    x=list(lags_range_diff),
    y=pacf_diff,
    marker_color='#43a047',
    name='PACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=2, col=2)

fig.add_hline(y=ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=-ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=2)

# --- Update Layout ---
fig.update_layout(
    title={
        'text': '<b>AR Process Analysis - Government Spending (Level & First Difference)</b><br>' +
                '<sub>ACF decays gradually | PACF cuts off at lag p | Pakistan (2010-2020)</sub>',
        'x': 0.5,
        'xanchor': 'center',
        'font': {'size': 20, 'color': '#1a1a1a', 'family': 'Arial Black'}
    },
    height=700,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='#fafafa',
    margin=dict(l=60, r=60, t=120, b=80),
    showlegend=False
)

# Update all axes
fig.update_xaxes(title_text="<b>Lag</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})
fig.update_yaxes(title_text="<b>Correlation</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})

# Add source annotation
fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.08,
    xanchor='center',
    showarrow=False,
    font={'size': 11, 'color': '#666'}
)

fig.show()
```

The ACF zero after lag 2 and PACF cuts off after lag 2 it indicate the series is stationary at first difference now confirm through ADF and KPSS test.

**MA process for government_expenditure**

```{python}
import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import acf, pacf
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# ==========================================
# MA PROCESS ANALYSIS FOR GOVERNMENT SPENDING
# ==========================================

# Prep series (ensure datetime index if you have a date column)
ts = df.copy()
if 'date' in ts.columns:
    ts['date'] = pd.to_datetime(ts['date'])
    ts = ts.set_index('date')
ts = ts.sort_index()

y_level = ts['government_spending'].dropna()
y_diff = y_level.diff().dropna()
nlags = 20

# ACF/PACF
acf_level = acf(y_level, nlags=nlags, fft=False)
pacf_level = pacf(y_level, nlags=nlags, method="ywmle")
acf_diff = acf(y_diff, nlags=nlags, fft=False)
pacf_diff = pacf(y_diff, nlags=nlags, method="ywmle")

conf_level = 1.96 / np.sqrt(len(y_level))
conf_diff = 1.96 / np.sqrt(len(y_diff))
lags = list(range(len(acf_level)))
lags_diff = list(range(len(acf_diff)))

# ==========================================
# COMPACT 2x2 LAYOUT: MA PROCESS ANALYSIS
# ==========================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        '<b>ACF - Level (cuts off at lag q)</b>',
        '<b>PACF - Level (decays gradually)</b>',
        '<b>ACF - First Diff (cuts off at lag q)</b>',
        '<b>PACF - First Diff (decays gradually)</b>'
    ),
    horizontal_spacing=0.12,
    vertical_spacing=0.15
)

# --- Row 1, Col 1: ACF at Level ---
fig.add_trace(go.Bar(
    x=lags,
    y=acf_level,
    marker_color='#e91e63',
    name='ACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=1, col=1)

fig.add_hline(y=conf_level, line_dash="dash", line_color="red", 
               line_width=1.5, row=1, col=1)
fig.add_hline(y=-conf_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=1)

# --- Row 1, Col 2: PACF at Level ---
fig.add_trace(go.Bar(
    x=lags,
    y=pacf_level,
    marker_color='#ff9800',
    name='PACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=1, col=2)

fig.add_hline(y=conf_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=-conf_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=2)

# --- Row 2, Col 1: ACF at First Difference ---
fig.add_trace(go.Bar(
    x=lags_diff,
    y=acf_diff,
    marker_color='#e91e63',
    name='ACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=2, col=1)

fig.add_hline(y=conf_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=-conf_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=1)

# --- Row 2, Col 2: PACF at First Difference ---
fig.add_trace(go.Bar(
    x=lags_diff,
    y=pacf_diff,
    marker_color='#ff9800',
    name='PACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=2, col=2)

fig.add_hline(y=conf_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=-conf_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=2)

# --- Update Layout ---
fig.update_layout(
    title={
        'text': '<b>MA Process Analysis - Government Spending (Level & First Difference)</b><br>' +
                '<sub>ACF cuts off at lag q | PACF decays gradually | Pakistan (2010-2020)</sub>',
        'x': 0.5,
        'xanchor': 'center',
        'font': {'size': 20, 'color': '#1a1a1a', 'family': 'Arial Black'}
    },
    height=700,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='#fafafa',
    margin=dict(l=60, r=60, t=120, b=80),
    showlegend=False
)

# Update all axes
fig.update_xaxes(title_text="<b>Lag</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})
fig.update_yaxes(title_text="<b>Correlation</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10}, range=[-1, 1])

# Add source annotation
fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.08,
    xanchor='center',
    showarrow=False,
    font={'size': 11, 'color': '#7f8c8d'}
)

fig.show()
```

The PACF go to zero exponentially and ACF cuts off after lag 2 it indicate the series is stationary at first difference now confirm through formal test.

**ADF and KPSS tests for government_spending**

```{python}
import pandas as pd
from statsmodels.tsa.stattools import adfuller, kpss

series = df['government_spending'].dropna()
diff1 = series.diff().dropna()

rows = []

def add_adf(x, label, reg, alpha=0.05):
    stat, pval, lags, nobs, crit = adfuller(
        x, regression=reg, autolag=None, maxlag=4  # fixed lag = 4
    )
    rows.append({
        "Test": "ADF",
        "Series": label,
        "Reg": reg,  # c = constant; ct = constant + trend
        "Stat": stat,
        "p-value": pval,
        "Lags": lags,
        "Obs": nobs,
        "Crit 1%": crit["1%"],
        "Crit 5%": crit["5%"],
        "Crit 10%": crit["10%"],
        "Stationary?": "✓" if pval < alpha else "x"  # H0: unit root
    })

def add_kpss(x, label, reg, alpha=0.05):
    stat, pval, lags, crit = kpss(
        x, regression=reg, nlags=4  # fixed lag = 4
    )
    rows.append({
        "Test": "KPSS",
        "Series": label,
        "Reg": reg,  # c = level stationarity; ct = trend stationarity
        "Stat": stat,
        "p-value": pval,
        "Lags": lags,
        "Crit 1%": crit["1%"],
        "Crit 5%": crit["5%"],
        "Crit 10%": crit["10%"],
        "Stationary?": "✓" if pval >= alpha else "x"  # H0: stationary
    })

for reg in ["c", "ct"]:
    add_adf(series, "Level", reg)
    add_kpss(series, "Level", reg)
    add_adf(diff1, "Diff1", reg)
    add_kpss(diff1, "Diff1", reg)

results = pd.DataFrame(rows)
display(results)
```

The government_spending series is stationary on first difference as confirmed by KPSS with drift , Trend and also 4 lags as we have seen the P-value (0.100000) of KPSS test is greater than 0.05 we fail to reject the null hypothesis and conclude that the series is stationary on first difference. So we use ARIMA(2,1,2) model for government_expenditure series.

**ARIMA (2,1,2) model for government_spending series**

```{python}
from statsmodels.tsa.arima.model import ARIMA
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import mean_squared_error, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# ==========================================
# PREPARE DATA
# ==========================================

# Prepare the time series
ts = df.copy()
if 'date' in ts.columns:
    ts['date'] = pd.to_datetime(ts['date'])
    ts = ts.set_index('date')
ts = ts.sort_index()

data = ts['government_spending'].dropna()

# Split data: train (all but last 4) and test (last 4 for validation)
train_data = data[:-4]
test_data = data[-4:]

print("=" * 80)
print("ARIMA MODEL COMPARISON FOR GOVERNMENT SPENDING")
print("=" * 80)
print(f"Total observations: {len(data)}")
print(f"Training observations: {len(train_data)}")
print(f"Test observations: {len(test_data)}")
print(f"Training range: {train_data.index[0]} to {train_data.index[-1]}")
print(f"Test range: {test_data.index[0]} to {test_data.index[-1]}")
print("=" * 80)

# ==========================================
# FIT ARIMA(2,1,2) MODEL
# ==========================================

print("\n" + "=" * 80)
print("FITTING ARIMA(2,1,2) MODEL")
print("=" * 80)

try:
    model_212 = ARIMA(train_data, order=(2, 1, 2))
    results_212 = model_212.fit()

    # Forecast 4 quarters ahead
    forecast_212 = results_212.get_forecast(steps=4)
    forecast_values_212 = forecast_212.predicted_mean
    forecast_ci_212 = forecast_212.conf_int(alpha=0.05)

    # Calculate RMSE and MAE
    rmse_212 = np.sqrt(mean_squared_error(test_data, forecast_values_212))
    mae_212 = mean_absolute_error(test_data, forecast_values_212)
    mape_212 = np.mean(np.abs((test_data - forecast_values_212) / test_data)) * 100

    print(f"\nAIC: {results_212.aic:.4f}")
    print(f"BIC: {results_212.bic:.4f}")
    print(f"RMSE: {rmse_212:.4f}")
    print(f"MAE: {mae_212:.4f}")
    print(f"MAPE: {mape_212:.2f}%")
    
except Exception as e:
    print(f"Error fitting ARIMA(2,1,2): {e}")
    results_212 = None

# ==========================================
# FIT ARIMA(2,1,3) MODEL
# ==========================================

print("\n" + "=" * 80)
print("FITTING ARIMA(2,1,3) MODEL")
print("=" * 80)

try:
    model_213 = ARIMA(train_data, order=(2, 1, 3))
    results_213 = model_213.fit()

    # Forecast 4 quarters ahead
    forecast_213 = results_213.get_forecast(steps=4)
    forecast_values_213 = forecast_213.predicted_mean
    forecast_ci_213 = forecast_213.conf_int(alpha=0.05)

    # Calculate RMSE and MAE
    rmse_213 = np.sqrt(mean_squared_error(test_data, forecast_values_213))
    mae_213 = mean_absolute_error(test_data, forecast_values_213)
    mape_213 = np.mean(np.abs((test_data - forecast_values_213) / test_data)) * 100

    print(f"\nAIC: {results_213.aic:.4f}")
    print(f"BIC: {results_213.bic:.4f}")
    print(f"RMSE: {rmse_213:.4f}")
    print(f"MAE: {mae_213:.4f}")
    print(f"MAPE: {mape_213:.2f}%")
    
except Exception as e:
    print(f"Error fitting ARIMA(2,1,3): {e}")
    results_213 = None

# ==========================================
# MODEL COMPARISON TABLE
# ==========================================

if results_212 is not None and results_213 is not None:
    print("\n" + "=" * 80)
    print("MODEL COMPARISON")
    print("=" * 80)
    comparison_df = pd.DataFrame({
        'Model': ['ARIMA(2,1,2)', 'ARIMA(2,1,3)'],
        'AIC': [results_212.aic, results_213.aic],
        'BIC': [results_212.bic, results_213.bic],
        'RMSE': [rmse_212, rmse_213],
        'MAE': [mae_212, mae_213],
        'MAPE%': [mape_212, mape_213]
    })
    print(comparison_df.to_string(index=False))
    print("=" * 80)

    # Determine best model
    best_model = 'ARIMA(2,1,2)' if rmse_212 < rmse_213 else 'ARIMA(2,1,3)'
    print(f"\n✓ Best Model (based on RMSE): {best_model}")
    print("=" * 80)

    # ==========================================
    # COMPACT 1x2 VISUALIZATION: SIDE-BY-SIDE COMPARISON
    # ==========================================

    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=(
            f'<b>ARIMA(2,1,2) | RMSE: {rmse_212:.2f}</b>',
            f'<b>ARIMA(2,1,3) | RMSE: {rmse_213:.2f}</b>'
        ),
        horizontal_spacing=0.10
    )

    # ============ LEFT PLOT: ARIMA(2,1,2) ============

    # Training data
    fig.add_trace(go.Scatter(
        x=train_data.index,
        y=train_data.values,
        mode='lines',
        name='Training',
        line=dict(color='#3498db', width=2),
        legendgroup='group1',
        showlegend=True,
        hovertemplate='<b>Training</b><br>%{x}: %{y:.2f}<extra></extra>'
    ), row=1, col=1)

    # Actual test data
    fig.add_trace(go.Scatter(
        x=test_data.index,
        y=test_data.values,
        mode='lines+markers',
        name='Actual',
        line=dict(color='#2ecc71', width=2.5),
        marker=dict(size=7),
        legendgroup='group1',
        showlegend=True,
        hovertemplate='<b>Actual</b><br>%{x}: %{y:.2f}<extra></extra>'
    ), row=1, col=1)

    # ARIMA(2,1,2) Forecast
    fig.add_trace(go.Scatter(
        x=test_data.index,
        y=forecast_values_212.values,
        mode='lines+markers',
        name='Forecast (2,1,2)',
        line=dict(color='#e74c3c', width=2, dash='dash'),
        marker=dict(size=7, symbol='x'),
        legendgroup='group1',
        showlegend=True,
        hovertemplate='<b>Forecast</b><br>%{x}: %{y:.2f}<extra></extra>'
    ), row=1, col=1)

    # Confidence interval for ARIMA(2,1,2)
    fig.add_trace(go.Scatter(
        x=test_data.index,
        y=forecast_ci_212.iloc[:, 1].values,
        fill=None,
        mode='lines',
        line_color='rgba(0,0,0,0)',
        showlegend=False,
        hoverinfo='skip'
    ), row=1, col=1)

    fig.add_trace(go.Scatter(
        x=test_data.index,
        y=forecast_ci_212.iloc[:, 0].values,
        fill='tonexty',
        mode='lines',
        line_color='rgba(0,0,0,0)',
        name='95% CI',
        fillcolor='rgba(231, 76, 60, 0.2)',
        legendgroup='group1',
        showlegend=True,
        hovertemplate='<b>95% CI</b><extra></extra>'
    ), row=1, col=1)

    # ============ RIGHT PLOT: ARIMA(2,1,3) ============

    # Training data
    fig.add_trace(go.Scatter(
        x=train_data.index,
        y=train_data.values,
        mode='lines',
        name='Training',
        line=dict(color='#3498db', width=2),
        legendgroup='group2',
        showlegend=False,
        hovertemplate='<b>Training</b><br>%{x}: %{y:.2f}<extra></extra>'
    ), row=1, col=2)

    # Actual test data
    fig.add_trace(go.Scatter(
        x=test_data.index,
        y=test_data.values,
        mode='lines+markers',
        name='Actual',
        line=dict(color='#2ecc71', width=2.5),
        marker=dict(size=7),
        legendgroup='group2',
        showlegend=False,
        hovertemplate='<b>Actual</b><br>%{x}: %{y:.2f}<extra></extra>'
    ), row=1, col=2)

    # ARIMA(2,1,3) Forecast
    fig.add_trace(go.Scatter(
        x=test_data.index,
        y=forecast_values_213.values,
        mode='lines+markers',
        name='Forecast (2,1,3)',
        line=dict(color='#9b59b6', width=2, dash='dash'),
        marker=dict(size=7, symbol='x'),
        legendgroup='group2',
        showlegend=False,
        hovertemplate='<b>Forecast</b><br>%{x}: %{y:.2f}<extra></extra>'
    ), row=1, col=2)

    # Confidence interval for ARIMA(2,1,3)
    fig.add_trace(go.Scatter(
        x=test_data.index,
        y=forecast_ci_213.iloc[:, 1].values,
        fill=None,
        mode='lines',
        line_color='rgba(0,0,0,0)',
        showlegend=False,
        hoverinfo='skip'
    ), row=1, col=2)

    fig.add_trace(go.Scatter(
        x=test_data.index,
        y=forecast_ci_213.iloc[:, 0].values,
        fill='tonexty',
        mode='lines',
        line_color='rgba(0,0,0,0)',
        name='95% CI',
        fillcolor='rgba(155, 89, 182, 0.2)',
        legendgroup='group2',
        showlegend=False,
        hovertemplate='<b>95% CI</b><extra></extra>'
    ), row=1, col=2)

    # ============ UPDATE LAYOUT ============

    fig.update_layout(
        title={
            'text': f'<b>ARIMA Model Comparison - Government Spending</b><br>' +
                    f'<sub>4-Quarter Forecast | Best Model: {best_model}</sub>',
            'y': 0.98,
            'x': 0.5,
            'xanchor': 'center',
            'font': dict(size=18, color='#1a1a1a', family='Arial Black')
        },
        height=550,
        width=1200,
        plot_bgcolor='white',
        paper_bgcolor='#f5f5f5',
        hovermode='x unified',
        legend=dict(
            orientation='h',
            x=0.5,
            y=-0.15,
            xanchor='center',
            bgcolor='rgba(255,255,255,0.8)'
        ),
        margin=dict(l=60, r=60, t=100, b=100)
    )

    # Update axes
    fig.update_xaxes(title_text="<b>Time Period</b>", showgrid=True, 
                     gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 9})
    fig.update_yaxes(title_text="<b>Government Spending</b>", showgrid=True, 
                     gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})

    # Add source annotation
    fig.add_annotation(
        text='<i>Source: Pakistan Bureau of Statistics</i>',
        xref='paper',
        yref='paper',
        x=0.5,
        y=-0.22,
        xanchor='center',
        showarrow=False,
        font=dict(size=10, color='#7f8c8d')
    )

    fig.show()

    # ==========================================
    # FORECAST DETAILS
    # ==========================================

    print("\n" + "=" * 80)
    print("FORECAST COMPARISON - 4 QUARTERS AHEAD")
    print("=" * 80)

    forecast_comparison = pd.DataFrame({
        'Quarter': test_data.index.astype(str),
        'Actual': test_data.values,
        'ARIMA(2,1,2)': forecast_values_212.values,
        'Error(2,1,2)': test_data.values - forecast_values_212.values,
        'ARIMA(2,1,3)': forecast_values_213.values,
        'Error(2,1,3)': test_data.values - forecast_values_213.values
    })

    print(forecast_comparison.to_string(index=False))
    print("=" * 80)

    print("\n✓ ARIMA Model Comparison Complete!")
```

The ARIMA (2,1,2) model for government_expenditure series has been selected based on its RMSE which is low comparetively ARIMA (2,13). The RMSE value for this model is 14.7361 which indicates a good fit to the data. This suggests that the model is effective in capturing the underlying patterns in Pakistan's government expenditure data, making it suitable for forecasting future government spending trends.

**Univariate Analysis of Net_revenue**

```{python}
import plotly.graph_objects as go

# --- 1. Prepare the Data ---
# Assuming 'df' is your pre-loaded DataFrame with the correct column name 'Net_revenue'
net_revenue_series = df['Net_revenue'].dropna()
rolling_avg = net_revenue_series.rolling(window=4).mean()

# --- 2. Create the Enhanced Interactive Plot ---
fig = go.Figure()

# Add the trace for the 4-Quarter Rolling Average first (so it's in the background)
fig.add_trace(go.Scatter(
    x=rolling_avg.index,
    y=rolling_avg,
    mode='lines',
    name='4-Quarter Rolling Average',
    line=dict(color='lightgrey', width=2, dash='dash'),
    hoverinfo='skip' # Hide hover info for the trend line to keep it clean
))

# Add the trace for the actual Quarterly Net Revenue
fig.add_trace(go.Scatter(
    x=net_revenue_series.index,
    y=net_revenue_series,
    mode='lines', # Cleaner look without markers
    name='Quarterly Net Revenue',
    line=dict(color='#1f77b4', width=2.5), # A strong, professional blue
    # Custom hover template for a better user experience
    hovertemplate='<b>%{x|%Y-%m-%d}</b><br>Net Revenue: %{y:,.0f}<extra></extra>'
))

# --- 3. Customize the Layout for a Clean, Modern Look ---
fig.update_layout(
    # Use a clean, well-regarded template
    template='seaborn',
    title=dict(
        text='<b>Quarterly Net Revenue in Pakistan</b>',
        font=dict(size=24, family="Arial"),
        x=0.5
    ),
    xaxis_title="Date",
    yaxis_title="Net Revenue",
    # Style the legend
    legend=dict(
        orientation="h", # Horizontal legend
        yanchor="bottom",
        y=1.02,
        xanchor="right",
        x=1
    ),
    # Add some breathing room
    margin=dict(l=80, r=40, t=100, b=80),
    # Add the source annotation
    annotations=[
        dict(
            text="Source: Pakistan Bureau of Statistics",
            showarrow=False,
            xref="paper", yref="paper",
            x=0, y=-0.2,
            font=dict(size=12, color="grey"),
            align="left"
        )
    ]
)

# Further refine the axes for a cleaner look
fig.update_xaxes(showgrid=False) # Hide vertical gridlines
fig.update_yaxes(gridwidth=1, gridcolor='lightgrey') # Make horizontal gridlines lighter

# Show the plot
fig.show()
```

The Net_revenue plot displays the trend of Pakistan's net revenue over time. The graph indicates fluctuations in net revenue, reflecting changes in government income from various sources such as taxes, fees, and other revenues. Overall, the trend shows periods of both growth and decline, which may be influenced by economic conditions and fiscal policies.

**Net_revenue Decompositions**

```{python}
from statsmodels.tsa.seasonal import seasonal_decompose
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# ==========================================
# PREPARE DATA
# ==========================================
net_revenue_series = df['Net_revenue'].dropna()

# ==========================================
# PERFORM ADDITIVE DECOMPOSITION
# ==========================================
decomposition = seasonal_decompose(net_revenue_series, model='additive', period=4)

# ==========================================
# COMPACT 2x2 LAYOUT (WITHOUT SEASONAL)
# ==========================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        '<b>Observed Series</b>',
        '<b>Trend Component</b>',
        '<b>Residual Component</b>',
        ''  # Empty placeholder for 4th position
    ),
    horizontal_spacing=0.12,
    vertical_spacing=0.15,
    specs=[
        [{"type": "scatter"}, {"type": "scatter"}],
        [{"type": "scatter"}, {"type": "scatter"}]
    ]
)

# --- Row 1, Col 1: Observed ---
fig.add_trace(
    go.Scatter(
        x=decomposition.observed.index,
        y=decomposition.observed,
        mode='lines',
        name='Observed',
        line=dict(color='#2c3e50', width=2),
        showlegend=False,
        hovertemplate='<b>Date</b>: %{x}<br><b>Net Revenue</b>: %{y:.2f}<extra></extra>'
    ),
    row=1, col=1
)

# --- Row 1, Col 2: Trend ---
fig.add_trace(
    go.Scatter(
        x=decomposition.trend.index,
        y=decomposition.trend,
        mode='lines',
        name='Trend',
        line=dict(color='#27ae60', width=2.5),
        showlegend=False,
        hovertemplate='<b>Date</b>: %{x}<br><b>Trend</b>: %{y:.2f}<extra></extra>'
    ),
    row=1, col=2
)

# --- Row 2, Col 1: Residual ---
fig.add_trace(
    go.Scatter(
        x=decomposition.resid.index,
        y=decomposition.resid,
        mode='markers',
        name='Residual',
        marker=dict(color='#e74c3c', size=5),
        showlegend=False,
        hovertemplate='<b>Date</b>: %{x}<br><b>Residual</b>: %{y:.2f}<extra></extra>'
    ),
    row=2, col=1
)

# Add zero line to residual plot
fig.add_hline(y=0, line_dash="dash", line_color="gray", line_width=1, row=2, col=1)

# --- Row 2, Col 2: Leave empty or add a note ---
fig.add_annotation(
    text='<i>Seasonal component<br>excluded from analysis</i>',
    xref='x4', yref='y4',
    x=0.5, y=0.5,
    xanchor='center', yanchor='middle',
    showarrow=False,
    font=dict(size=14, color='#7f8c8d', family='Arial'),
    align='center'
)

# Hide the 4th subplot axes
fig.update_xaxes(visible=False, row=2, col=2)
fig.update_yaxes(visible=False, row=2, col=2)

# ==========================================
# UPDATE LAYOUT
# ==========================================

fig.update_layout(
    title={
        'text': '<b>Net Revenue - Time Series Decomposition (Additive Model)</b><br>' +
                '<sub>Observed, Trend & Residual Components (Seasonal Excluded)</sub>',
        'x': 0.5,
        'xanchor': 'center',
        'font': {'size': 20, 'color': '#1a1a1a', 'family': 'Arial Black'}
    },
    height=700,
    width=1200,
    showlegend=False,
    plot_bgcolor='white',
    paper_bgcolor='#fafafa',
    margin=dict(l=60, r=60, t=100, b=80)
)

# Update axes
fig.update_xaxes(title_text="<b>Date</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=2, col=1)
fig.update_xaxes(title_text="<b>Date</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=1, col=2)
fig.update_xaxes(title_text="<b>Date</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=1, col=1)

fig.update_yaxes(title_text="<b>Net Revenue</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=1, col=1)
fig.update_yaxes(title_text="<b>Trend</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=1, col=2)
fig.update_yaxes(title_text="<b>Residual</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', row=2, col=1)

# Add source annotation
fig.add_annotation(
    text='<b>Source: Pakistan Bureau of Statistics</b>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.08,
    xanchor='center',
    showarrow=False,
    font=dict(size=12, color='#2c3e50')
)

fig.show()
```

The time series decomposition of Net_revenue reveals the underlying components that contribute to the overall pattern of Pakistan's net revenue over time. The trend component indicates periods of both growth and decline, reflecting changes in government income from various sources such as taxes, fees, and other revenues.The residual component represents irregular variations that are not explained by the trend or seasonal factors, indicating the presence of unexpected events or changes in fiscal policy. This decomposition provides valuable insights into the dynamics of net revenue in Pakistan, aiding in better economic planning and analysis.

**ACF and PACF Analysis of AR Process for Net_revenue**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.graphics.tsaplots import acf, pacf

# ==========================================
# ACF AND PACF ANALYSIS FOR NET REVENUE - AR PROCESS
# ==========================================

# Prepare data
ts = df.copy()
if 'date' in ts.columns:
    ts['date'] = pd.to_datetime(ts['date'])
    ts = ts.set_index('date')
ts = ts.sort_index()

# Use Net_revenue column
netrev_data = ts['Net_revenue'].dropna()
netrev_diff = netrev_data.diff().dropna()

nlags = 20

# Calculate ACF and PACF
acf_level = acf(netrev_data, nlags=nlags, fft=False)
pacf_level = pacf(netrev_data, nlags=nlags, method="ywmle")
acf_diff = acf(netrev_diff, nlags=nlags, fft=False)
pacf_diff = pacf(netrev_diff, nlags=nlags, method="ywmle")

# Confidence intervals
ci_level = 1.96 / np.sqrt(len(netrev_data))
ci_diff = 1.96 / np.sqrt(len(netrev_diff))

# ==========================================
# COMPACT 2x2 LAYOUT: AR PROCESS ANALYSIS
# ==========================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        '<b>ACF - Level (decays gradually)</b>',
        '<b>PACF - Level (cuts off at lag p)</b>',
        '<b>ACF - First Diff (decays gradually)</b>',
        '<b>PACF - First Diff (cuts off at lag p)</b>'
    ),
    horizontal_spacing=0.12,
    vertical_spacing=0.15
)

# --- Row 1, Col 1: ACF at Level ---
lags_range = range(len(acf_level))
fig.add_trace(go.Bar(
    x=list(lags_range),
    y=acf_level,
    marker_color='#1e88e5',
    name='ACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=1, col=1)

fig.add_hline(y=ci_level, line_dash="dash", line_color="red", 
               line_width=1.5, row=1, col=1)
fig.add_hline(y=-ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=1)

# --- Row 1, Col 2: PACF at Level ---
fig.add_trace(go.Bar(
    x=list(lags_range),
    y=pacf_level,
    marker_color='#43a047',
    name='PACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=1, col=2)

fig.add_hline(y=ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=-ci_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=2)

# --- Row 2, Col 1: ACF at First Difference ---
lags_range_diff = range(len(acf_diff))
fig.add_trace(go.Bar(
    x=list(lags_range_diff),
    y=acf_diff,
    marker_color='#1e88e5',
    name='ACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=2, col=1)

fig.add_hline(y=ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=-ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=1)

# --- Row 2, Col 2: PACF at First Difference ---
fig.add_trace(go.Bar(
    x=list(lags_range_diff),
    y=pacf_diff,
    marker_color='#43a047',
    name='PACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=2, col=2)

fig.add_hline(y=ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=-ci_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=2)

# --- Update Layout ---
fig.update_layout(
    title={
        'text': '<b>AR Process Analysis - Net Revenue (Level & First Difference)</b><br>' +
                '<sub>ACF decays gradually | PACF cuts off at lag p | Pakistan (2010-2020)</sub>',
        'x': 0.5,
        'xanchor': 'center',
        'font': {'size': 20, 'color': '#1a1a1a', 'family': 'Arial Black'}
    },
    height=700,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='#fafafa',
    margin=dict(l=60, r=60, t=120, b=80),
    showlegend=False
)

# Update all axes
fig.update_xaxes(title_text="<b>Lag</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})
fig.update_yaxes(title_text="<b>Correlation</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})

# Add source annotation
fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.08,
    xanchor='center',
    showarrow=False,
    font={'size': 11, 'color': '#666'}
)

fig.show()
```

The ACF exponentially go to zero after 4 lags at level and on first difference after 3 lags so it indicate the series is stationary on level and also first difference now confirm through ADF and KPSS test.

**ACF and PACF Analysis of MA process for Net_revenue**

```{python}
import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import acf, pacf
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# ==========================================
# MA PROCESS ANALYSIS FOR NET REVENUE
# ==========================================

# Prep series (ensure datetime index if you have a date column)
ts = df.copy()
if 'date' in ts.columns:
    ts['date'] = pd.to_datetime(ts['date'])
    ts = ts.set_index('date')
ts = ts.sort_index()

y_level = ts['Net_revenue'].dropna()
y_diff = y_level.diff().dropna()
nlags = 20

# ACF/PACF
acf_level = acf(y_level, nlags=nlags, fft=False)
pacf_level = pacf(y_level, nlags=nlags, method="ywmle")
acf_diff = acf(y_diff, nlags=nlags, fft=False)
pacf_diff = pacf(y_diff, nlags=nlags, method="ywmle")

conf_level = 1.96 / np.sqrt(len(y_level))
conf_diff = 1.96 / np.sqrt(len(y_diff))
lags = list(range(len(acf_level)))
lags_diff = list(range(len(acf_diff)))

# ==========================================
# COMPACT 2x2 LAYOUT: MA PROCESS ANALYSIS
# ==========================================

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        '<b>ACF - Level (cuts off at lag q)</b>',
        '<b>PACF - Level (decays gradually)</b>',
        '<b>ACF - First Diff (cuts off at lag q)</b>',
        '<b>PACF - First Diff (decays gradually)</b>'
    ),
    horizontal_spacing=0.12,
    vertical_spacing=0.15
)

# --- Row 1, Col 1: ACF at Level ---
fig.add_trace(go.Bar(
    x=lags,
    y=acf_level,
    marker_color='#e91e63',
    name='ACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=1, col=1)

fig.add_hline(y=conf_level, line_dash="dash", line_color="red", 
               line_width=1.5, row=1, col=1)
fig.add_hline(y=-conf_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=1)

# --- Row 1, Col 2: PACF at Level ---
fig.add_trace(go.Bar(
    x=lags,
    y=pacf_level,
    marker_color='#ff9800',
    name='PACF Level',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=1, col=2)

fig.add_hline(y=conf_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=-conf_level, line_dash="dash", line_color="red",
               line_width=1.5, row=1, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=1, col=2)

# --- Row 2, Col 1: ACF at First Difference ---
fig.add_trace(go.Bar(
    x=lags_diff,
    y=acf_diff,
    marker_color='#e91e63',
    name='ACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>ACF: %{y:.3f}<extra></extra>'
), row=2, col=1)

fig.add_hline(y=conf_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=-conf_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=1)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=1)

# --- Row 2, Col 2: PACF at First Difference ---
fig.add_trace(go.Bar(
    x=lags_diff,
    y=pacf_diff,
    marker_color='#ff9800',
    name='PACF Diff',
    showlegend=False,
    hovertemplate='<b>Lag %{x}</b><br>PACF: %{y:.3f}<extra></extra>'
), row=2, col=2)

fig.add_hline(y=conf_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=-conf_diff, line_dash="dash", line_color="red",
               line_width=1.5, row=2, col=2)
fig.add_hline(y=0, line_color="black", line_width=1, row=2, col=2)

# --- Update Layout ---
fig.update_layout(
    title={
        'text': '<b>MA Process Analysis - Net Revenue (Level & First Difference)</b><br>' +
                '<sub>ACF cuts off at lag q | PACF decays gradually | Pakistan (2010-2020)</sub>',
        'x': 0.5,
        'xanchor': 'center',
        'font': {'size': 20, 'color': '#1a1a1a', 'family': 'Arial Black'}
    },
    height=700,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='#fafafa',
    margin=dict(l=60, r=60, t=120, b=80),
    showlegend=False
)

# Update all axes
fig.update_xaxes(title_text="<b>Lag</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})
fig.update_yaxes(title_text="<b>Correlation</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10}, range=[-1, 1])

# Add source annotation
fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.08,
    xanchor='center',
    showarrow=False,
    font={'size': 11, 'color': '#7f8c8d'}
)

fig.show()
```

THe PACf exponentially go to zero after 2 lags at level and on first difference after 2 lags so it indicate the series is stationary on level and also first difference now confirm through formal test.

**ADF and KPSS tests for Net_revenue**

```{python}
import pandas as pd
from statsmodels.tsa.stattools import adfuller, kpss

series = df['Net_revenue'].dropna()
diff1 = series.diff().dropna()
rows = []

def add_adf(x, label, reg, alpha=0.05):
    stat, pval, lags, nobs, crit = adfuller(
        x, regression=reg, autolag=None, maxlag=4  # fixed lag = 4
    )
    rows.append({
        "Test": "ADF",
        "Series": label,
        "Reg": reg,  # c = constant; ct = constant+trend
        "Stat": stat,
        "p-value": pval,
        "Lags": lags,
        "Obs": nobs,
        "Crit 1%": crit["1%"],
        "Crit 5%": crit["5%"],
        "Crit 10%": crit["10%"],
        "Stationary?": "✓" if pval < alpha else "x"  # H0: unit root
    })

def add_kpss(x, label, reg, alpha=0.05):
    stat, pval, lags, crit = kpss(
        x, regression=reg, nlags=4  # fixed lag = 4
    )
    rows.append({
        "Test": "KPSS",
        "Series": label,
        "Reg": reg,  # c = level stationarity; ct = trend stationarity
        "Stat": stat,
        "p-value": pval,
        "Lags": lags,
        "Crit 1%": crit["1%"],
        "Crit 5%": crit["5%"],
        "Crit 10%": crit["10%"],
        "Stationary?": "✓" if pval >= alpha else "x"  # H0: stationary
    })

for reg in ["c", "ct"]:
    add_adf(series, "Level", reg)
    add_kpss(series, "Level", reg)
    add_adf(diff1, "Diff1", reg)
    add_kpss(diff1, "Diff1", reg)

results = pd.DataFrame(rows)
results["p-value"] = results["p-value"].map(lambda v: f"{v:.6f}")
display(results)
```

According to ADF test the Net_revenue series is stationary at level as the p-value (0.000) with drift and trend and also with 4 lags is less than 0.05. So we use ARIMA(1,0,4) model for Net_revenue series.

**ARIMA (1,0,4) model for Net_revenue series**

```{python}
from statsmodels.tsa.arima.model import ARIMA
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# ============================================
# PREPARE DATA
# ============================================

data = df['Net_revenue'].dropna()

# Split data: train (all but last 4) and test (last 4 for validation)
train_data = data[:-4]
test_data = data[-4:]

print("=" * 80)
print("ARIMA MODEL COMPARISON FOR Net_revenue")
print("=" * 80)
print(f"Total observations: {len(data)}")
print(f"Training observations: {len(train_data)}")
print(f"Test observations: {len(test_data)}")
print("=" * 80)

# ============================================
# FIT ARIMA(1,0,4) MODEL
# ============================================

print("\n" + "=" * 80)
print("FITTING ARIMA(1,0,4) MODEL")
print("=" * 80)

model_104 = ARIMA(train_data, order=(1, 0, 4))
results_104 = model_104.fit()

# Forecast 4 quarters ahead
forecast_104 = results_104.get_forecast(steps=4)
forecast_values_104 = forecast_104.predicted_mean
forecast_ci_104 = forecast_104.conf_int(alpha=0.05)

# Calculate RMSE
rmse_104 = np.sqrt(mean_squared_error(test_data, forecast_values_104))

print(f"\nAIC: {results_104.aic:.4f}")
print(f"BIC: {results_104.bic:.4f}")
print(f"RMSE (Root Mean Squared Error): {rmse_104:.6f}")

# ============================================
# FIT ARIMA(1,1,4) MODEL
# ============================================

print("\n" + "=" * 80)
print("FITTING ARIMA(1,1,4) MODEL")
print("=" * 80)

model_114 = ARIMA(train_data, order=(1, 1, 4))
results_114 = model_114.fit()

# Forecast 4 quarters ahead
forecast_114 = results_114.get_forecast(steps=4)
forecast_values_114 = forecast_114.predicted_mean
forecast_ci_114 = forecast_114.conf_int(alpha=0.05)

# Calculate RMSE
rmse_114 = np.sqrt(mean_squared_error(test_data, forecast_values_114))

print(f"\nAIC: {results_114.aic:.4f}")
print(f"BIC: {results_114.bic:.4f}")
print(f"RMSE (Root Mean Squared Error): {rmse_114:.6f}")

# ============================================
# MODEL COMPARISON TABLE
# ============================================

print("\n" + "=" * 80)
print("MODEL COMPARISON")
print("=" * 80)
comparison_df = pd.DataFrame({
    'Model': ['ARIMA(1,0,4)', 'ARIMA(1,1,4)'],
    'AIC': [results_104.aic, results_114.aic],
    'BIC': [results_104.bic, results_114.bic],
    'RMSE': [rmse_104, rmse_114]
})
print(comparison_df.to_string(index=False))
print("=" * 80)

# Determine best model
best_model = 'ARIMA(1,0,4)' if rmse_104 < rmse_114 else 'ARIMA(1,1,4)'
print(f"\n✓ Best Model (based on RMSE): {best_model}")
print("=" * 80)

# ============================================
# COMPACT 1x2 VISUALIZATION: SIDE-BY-SIDE COMPARISON
# ============================================

fig = make_subplots(
    rows=1, cols=2,
    subplot_titles=(
        f'<b>ARIMA(1,0,4) | RMSE: {rmse_104:.4f}</b>',
        f'<b>ARIMA(1,1,4) | RMSE: {rmse_114:.4f}</b>'
    ),
    horizontal_spacing=0.10
)

# ============ LEFT PLOT: ARIMA(1,0,4) ============

# Training data
fig.add_trace(go.Scatter(
    x=train_data.index.astype(str),
    y=train_data.values,
    mode='lines',
    name='Training',
    line=dict(color='#3498db', width=2),
    legendgroup='group1',
    showlegend=True,
    hovertemplate='<b>Training</b><br>%{x}: %{y:.2f}<extra></extra>'
), row=1, col=1)

# Actual test data
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=test_data.values,
    mode='lines+markers',
    name='Actual',
    line=dict(color='#2ecc71', width=2.5),
    marker=dict(size=7),
    legendgroup='group1',
    showlegend=True,
    hovertemplate='<b>Actual</b><br>%{x}: %{y:.2f}<extra></extra>'
), row=1, col=1)

# ARIMA(1,0,4) Forecast
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_values_104.values,
    mode='lines+markers',
    name='Forecast (1,0,4)',
    line=dict(color='#e74c3c', width=2, dash='dash'),
    marker=dict(size=7, symbol='x'),
    legendgroup='group1',
    showlegend=True,
    hovertemplate='<b>Forecast</b><br>%{x}: %{y:.2f}<extra></extra>'
), row=1, col=1)

# Confidence interval for ARIMA(1,0,4)
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_104.iloc[:, 1].values,
    fill=None,
    mode='lines',
    line_color='rgba(0,0,0,0)',
    showlegend=False,
    hoverinfo='skip'
), row=1, col=1)

fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_104.iloc[:, 0].values,
    fill='tonexty',
    mode='lines',
    line_color='rgba(0,0,0,0)',
    name='95% CI',
    fillcolor='rgba(231, 76, 60, 0.2)',
    legendgroup='group1',
    showlegend=True,
    hovertemplate='<b>95% CI</b><extra></extra>'
), row=1, col=1)

# ============ RIGHT PLOT: ARIMA(1,1,4) ============

# Training data
fig.add_trace(go.Scatter(
    x=train_data.index.astype(str),
    y=train_data.values,
    mode='lines',
    name='Training',
    line=dict(color='#3498db', width=2),
    legendgroup='group2',
    showlegend=False,
    hovertemplate='<b>Training</b><br>%{x}: %{y:.2f}<extra></extra>'
), row=1, col=2)

# Actual test data
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=test_data.values,
    mode='lines+markers',
    name='Actual',
    line=dict(color='#2ecc71', width=2.5),
    marker=dict(size=7),
    legendgroup='group2',
    showlegend=False,
    hovertemplate='<b>Actual</b><br>%{x}: %{y:.2f}<extra></extra>'
), row=1, col=2)

# ARIMA(1,1,4) Forecast
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_values_114.values,
    mode='lines+markers',
    name='Forecast (1,1,4)',
    line=dict(color='#9b59b6', width=2, dash='dash'),
    marker=dict(size=7, symbol='x'),
    legendgroup='group2',
    showlegend=False,
    hovertemplate='<b>Forecast</b><br>%{x}: %{y:.2f}<extra></extra>'
), row=1, col=2)

# Confidence interval for ARIMA(1,1,4)
fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_114.iloc[:, 1].values,
    fill=None,
    mode='lines',
    line_color='rgba(0,0,0,0)',
    showlegend=False,
    hoverinfo='skip'
), row=1, col=2)

fig.add_trace(go.Scatter(
    x=test_data.index.astype(str),
    y=forecast_ci_114.iloc[:, 0].values,
    fill='tonexty',
    mode='lines',
    line_color='rgba(0,0,0,0)',
    name='95% CI',
    fillcolor='rgba(155, 89, 182, 0.2)',
    legendgroup='group2',
    showlegend=False,
    hovertemplate='<b>95% CI</b><extra></extra>'
), row=1, col=2)

# ============ UPDATE LAYOUT ============

fig.update_layout(
    title={
        'text': f'<b>ARIMA Model Comparison - Net Revenue</b><br>' +
                f'<sub>4-Quarter Forecast | Best Model: {best_model}</sub>',
        'y': 0.98,
        'x': 0.5,
        'xanchor': 'center',
        'font': dict(size=18, color='#1a1a1a', family='Arial Black')
    },
    height=550,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='#f5f5f5',
    hovermode='x unified',
    legend=dict(
        orientation='h',
        x=0.5,
        y=-0.15,
        xanchor='center',
        bgcolor='rgba(255,255,255,0.8)'
    ),
    margin=dict(l=60, r=60, t=100, b=100)
)

# Update axes
fig.update_xaxes(title_text="<b>Time Period</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 9})
fig.update_yaxes(title_text="<b>Net Revenue</b>", showgrid=True, 
                 gridcolor='rgba(200,200,200,0.3)', tickfont={'size': 10})

# Add source annotation
fig.add_annotation(
    text='<i>Source: Pakistan Bureau of Statistics</i>',
    xref='paper',
    yref='paper',
    x=0.5,
    y=-0.22,
    xanchor='center',
    showarrow=False,
    font=dict(size=10, color='#7f8c8d')
)

fig.show()

# ============================================
# FORECAST DETAILS
# ============================================

print("\n" + "=" * 80)
print("FORECAST COMPARISON - 4 QUARTERS AHEAD")
print("=" * 80)

forecast_comparison = pd.DataFrame({
    'Quarter': [f'Q+{i}' for i in range(1, 5)],
    'Actual': test_data.values,
    'ARIMA(1,0,4)': forecast_values_104.values,
    'Error(1,0,4)': test_data.values - forecast_values_104.values,
    'ARIMA(1,1,4)': forecast_values_114.values,
    'Error(1,1,4)': test_data.values - forecast_values_114.values
})

print(forecast_comparison.to_string(index=False))
print("=" * 80)

print("\n✓ ARIMA Model Comparison Complete!")
```

The ARIMA (1,0,4) model for Net_revenue series has been selected based on its RMSE which is low comparetively ARIMA (1,1,4). The RMSE value for this model is 5092 which indicates a good fit to the data. This suggests that the model is effective in capturing the underlying patterns in Pakistan's net revenue data, making it suitable for forecasting future net revenue trends.

***First difference VAR***

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.tsa.api import VAR
from statsmodels.tsa.stattools import grangercausalitytests
import warnings
warnings.filterwarnings('ignore')

# ============================================
# PREPARE DATA - FIRST DIFFERENCE VAR
# ============================================

# I(1) variables - need first differencing
df['log_gdp_diff'] = df['log_gdp'].diff()
df['cpi_diff'] = df['CPI_Quarterly_Avg'].diff()
df['gov_spending_diff'] = df['government_spending'].diff()

# I(0) variables - use levels
df['interest_rate_level'] = df['interest_rate']
df['net_revenue_level'] = df['Net_revenue']

# Combine for VAR
var_data = df[['log_gdp_diff', 'cpi_diff', 'gov_spending_diff', 
               'interest_rate_level', 'net_revenue_level']].dropna()

# Short names for tables/charts (Stock & Watson style)
var_data.columns = ['GDP', 'CPI', 'GovSpend', 'IntRate', 'NetRev']

n_obs = len(var_data)
n_vars = len(var_data.columns)

# ============================================
# FIT VAR MODEL
# ============================================

model = VAR(var_data)
max_lags_to_test = min(4, int((n_obs - 1) / n_vars) - 1)
lag_order_results = model.select_order(maxlags=max_lags_to_test)
optimal_lag = lag_order_results.bic

var_model = model.fit(optimal_lag)

print("=" * 80)
print(f"FIRST DIFFERENCE VAR({optimal_lag}) MODEL")
print("=" * 80)
print(f"Variables: GDP(Δ), CPI(Δ), GovSpend(Δ), IntRate, NetRev")
print(f"Observations: {var_model.nobs}")
print("=" * 80)

# ============================================
# A. GRANGER CAUSALITY TESTS (STOCK & WATSON STYLE)
# ============================================

variables = var_data.columns.tolist()
granger_matrix = pd.DataFrame(index=variables, columns=variables)

for caused in variables:
    for causing in variables:
        if caused == causing:
            granger_matrix.loc[causing, caused] = 0.00
        else:
            test_data = var_data[[caused, causing]]
            try:
                gc_result = grangercausalitytests(test_data, maxlag=optimal_lag, verbose=False)
                p_values = [gc_result[i+1][0]['ssr_ftest'][1] for i in range(optimal_lag)]
                min_p = min(p_values)
                granger_matrix.loc[causing, caused] = round(min_p, 2)
            except:
                granger_matrix.loc[causing, caused] = np.nan

print("\n" + "=" * 80)
print("A. GRANGER-CAUSALITY TESTS")
print("=" * 80)
print("Dependent Variable in Regression (p-values)")
print("-" * 80)
print("\nRegressor")
print(granger_matrix.to_string())
print("\nNote: p-values < 0.05 indicate significant Granger causality")
print("=" * 80)

# ============================================
# B. VARIANCE DECOMPOSITION (FEVD)
# ============================================

# Determine appropriate IRF periods based on sample size
irf_periods = min(12, n_obs // 2)
fevd = var_model.fevd(irf_periods)
fevd_summary = fevd.decomp

print(f"\nFEVD array shape: {fevd_summary.shape}")
print(f"Available periods: {fevd_summary.shape[0]}")

# Adjust forecast horizons based on ACTUAL available periods
forecast_horizons = [h for h in [1, 4, 8, 12] if h <= fevd_summary.shape[0]]

print("\n" + "=" * 80)
print("B. VARIANCE DECOMPOSITIONS FROM THE RECURSIVE VAR")
print("=" * 80)
print(f"Note: Showing horizons {forecast_horizons} (based on available data)")
print("=" * 80)

for var_idx, var_name in enumerate(variables):
    print(f"\nB.{var_idx+1}. Variance Decomposition of {var_name}")
    print("-" * 80)
    print(f"{'Forecast':<12} {'Forecast':<18} {'Variance Decomposition'}")
    print(f"{'Horizon':<12} {'Standard Error':<18} {'(Percentage Points)'}")
    print(f"{'':<30} {' '.join([f'{v:>8}' for v in variables])}")
    print("-" * 80)
    
    for h in forecast_horizons:
        h_idx = h - 1  # Convert to 0-based index
        
        # Forecast standard error (simplified calculation)
        # This is the cumulative standard deviation up to horizon h
        se = np.sqrt(np.sum(fevd_summary[h_idx, var_idx, :]))
        
        # Get contributions at this horizon
        contributions = fevd_summary[h_idx, var_idx, :] * 100
        
        print(f"{h:<12} {se:<18.2f} {' '.join([f'{c:>8.0f}' for c in contributions])}")
    
    print("-" * 80)

# ============================================
# C. IMPULSE RESPONSE FUNCTIONS (STOCK & WATSON STYLE)
# ============================================

print("\n" + "=" * 80)
print("C. IMPULSE RESPONSE FUNCTIONS")
print("=" * 80)

irf = var_model.irf(irf_periods)
irf_results = irf.irfs

# Create Stock & Watson style IRF plot
fig = make_subplots(
    rows=n_vars, cols=n_vars,
    subplot_titles=[f'{impulse} Shock to<br>{response}' 
                    for response in variables 
                    for impulse in variables],
    vertical_spacing=0.06,
    horizontal_spacing=0.08
)

# Plot each IRF
for impulse_idx, impulse_var in enumerate(variables):
    for response_idx, response_var in enumerate(variables):
        row = response_idx + 1
        col = impulse_idx + 1
        
        irf_values = irf_results[:, response_idx, impulse_idx]
        periods = list(range(len(irf_values)))
        
        # Add IRF line
        fig.add_trace(
            go.Scatter(
                x=periods,
                y=irf_values,
                mode='lines',
                line=dict(color='black', width=2),
                name=f'{impulse_var} → {response_var}',
                showlegend=False,
                hovertemplate='<b>Lag %{x}</b><br>Response: %{y:.4f}<extra></extra>'
            ),
            row=row, col=col
        )
        
        # Add confidence bands (simple ±2 SE)
        try:
            # Calculate standard error bands (approximation)
            stderr = np.std(irf_values) / np.sqrt(len(irf_values))
            upper_band = irf_values + 1.96 * stderr
            lower_band = irf_values - 1.96 * stderr
            
            fig.add_trace(
                go.Scatter(
                    x=periods,
                    y=upper_band,
                    mode='lines',
                    line=dict(color='gray', width=1, dash='dot'),
                    showlegend=False,
                    hoverinfo='skip'
                ),
                row=row, col=col
            )
            
            fig.add_trace(
                go.Scatter(
                    x=periods,
                    y=lower_band,
                    mode='lines',
                    line=dict(color='gray', width=1, dash='dot'),
                    showlegend=False,
                    hoverinfo='skip'
                ),
                row=row, col=col
            )
        except:
            pass
        
        # Add zero line
        fig.add_hline(y=0, line_dash="solid", line_color="gray", 
                     line_width=0.5, row=row, col=col)
        
        # Add blue box for diagonal (own shocks) - Stock & Watson style
        if impulse_idx == response_idx:
            y_min = min(irf_values) if min(irf_values) < 0 else 0
            y_max = max(irf_values) if max(irf_values) > 0 else 0
            
            fig.add_shape(
                type="rect",
                x0=-0.5, x1=len(periods)-0.5,
                y0=y_min*1.1 if y_min < 0 else y_min*0.9,
                y1=y_max*1.1 if y_max > 0 else y_max*0.9,
                line=dict(color="blue", width=3),
                fillcolor="rgba(0,0,0,0)",
                row=row, col=col
            )

# Update layout (Stock & Watson style)
fig.update_layout(
    title={
        'text': '<b>Impulse Responses in the First Difference VAR</b><br>' +
                f'<sub>GDP(Δ), CPI(Δ), GovSpend(Δ), IntRate, NetRev</sub>',
        'y':0.98,
        'x':0.5,
        'xanchor': 'center',
        'font': dict(size=16, color='black', family='Times New Roman')
    },
    height=1200,
    width=1400,
    plot_bgcolor='white',
    paper_bgcolor='white',
    font=dict(size=9, family='Times New Roman'),
    margin=dict(l=60, r=40, t=100, b=60)
)

# Update axes (Stock & Watson style)
fig.update_xaxes(
    title_text="Lag",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.update_yaxes(
    title_text="Percent",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.show()

# ============================================
# SUMMARY TABLE
# ============================================

print("\n" + "=" * 80)
print("SUMMARY - FIRST DIFFERENCE VAR MODEL")
print("=" * 80)
print(f"Lag Order: {optimal_lag}")
print(f"Observations: {var_model.nobs}")
print(f"AIC: {var_model.aic:.2f}")
print(f"BIC: {var_model.bic:.2f}")
print(f"HQIC: {var_model.hqic:.2f}")
print(f"IRF Periods: {irf_periods}")
print(f"FEVD Periods Available: {fevd_summary.shape[0]}")
print("\nVariables:")
print("  I(1) - Differenced: GDP, CPI, GovSpend")
print("  I(0) - Levels: IntRate, NetRev")
print("=" * 80)

# ============================================
# EXPORT TABLES TO CSV
# ============================================

# Granger Causality Table
granger_matrix.to_csv('granger_causality_table.csv')
print("\n✓ Granger causality table saved to 'granger_causality_table.csv'")

# FEVD Tables
for var_idx, var_name in enumerate(variables):
    fevd_table_data = []
    for h in forecast_horizons:
        h_idx = h - 1
        se = np.sqrt(np.sum(fevd_summary[h_idx, var_idx, :]))
        contributions = fevd_summary[h_idx, var_idx, :] * 100
        
        row = {'Horizon': h, 'Std_Error': se}
        for v_idx, v_name in enumerate(variables):
            row[v_name] = contributions[v_idx]
        fevd_table_data.append(row)
    
    fevd_df = pd.DataFrame(fevd_table_data)
    fevd_df.to_csv(f'fevd_table_{var_name}.csv', index=False)
    print(f"✓ FEVD table for {var_name} saved to 'fevd_table_{var_name}.csv'")

print("\n" + "=" * 80)
print("✓ FIRST DIFFERENCE VAR ANALYSIS COMPLETE (STOCK & WATSON STYLE)")
print("=" * 80)
```

The VAR results show that GDP and CPI are the two most influential variables in the system because they Granger-cause several others, meaning past movements in GDP and inflation help predict changes in key macroeconomic variables. CPI is especially important, influencing GDP, interest rates, and government spending, while government spending mainly predicts itself and interest rates. From the variance decompositions, we see that over longer horizons (4 periods), Government Spending shocks explain most of the variation in GDP and CPI (around 60–65%), meaning fiscal policy plays a major role in driving economic activity and inflation. Interest rates are also strongly affected by government spending and CPI, showing a policy-sensitive environment. Net Revenue becomes more influenced by CPI and government spending over time, indicating fiscal revenues respond to inflationary and policy conditions. Overall, the system is fiscal-policy-dominated, inflation-sensitive, and shows strong interactions where government spending shocks are the main source of macroeconomic fluctuations, while interest rate and revenue shocks play a relatively small role. And the impulse responses show that a shock to GDP causes GDP itself to fall sharply at first, suggesting strong short-run mean reversion in economic activity, before stabilizing after a few periods. A CPI shock to CPI produces a very large and immediate spike, followed by a gradual decline, meaning inflation reacts strongly to its own shocks but then slowly returns to a normal path—indicating persistent inflation dynamics. A government spending shock to government spending initially pushes spending upward but then quickly reverses and becomes negative before stabilizing, reflecting short-run policy adjustments or budget corrections after a fiscal spike. An interest rate shock to interest rates causes a significant and long-lasting decline, showing strong monetary policy inertia, where an initial tightening is followed by systematic easing. Finally, a Net Revenue shock to Net Revenue generates a sharp but temporary increase, followed by several oscillations before returning to baseline, suggesting tax revenues react quickly to fiscal or economic shocks but stabilize only after several periods. Overall, the IRFs indicate that CPI and GovSpend shocks are highly persistent, GDP self-shocks revert quickly, interest rate shocks propagate strongly over time, and NetRev shocks create temporary volatility but eventually stabilize.

**Structural VAR Analysis**

```{python}
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.tsa.api import VAR
from scipy.linalg import cholesky
import warnings
warnings.filterwarnings('ignore')

# ============================================
# PREPARE DATA - STRUCTURAL VAR (BLANCHARD-PEROTTI ORDERING)
# ============================================

# I(1) variables - need first differencing
df['log_gdp_diff'] = df['log_gdp'].diff()
df['cpi_diff'] = df['CPI_Quarterly_Avg'].diff()
df['gov_spending_diff'] = df['government_spending'].diff()

# I(0) variables - use levels
df['interest_rate_level'] = df['interest_rate']
df['net_revenue_level'] = df['Net_revenue']

# BLANCHARD-PEROTTI ORDERING (for institutional identification):
# 1. NetRev (Tax) - automatic stabilizers respond to GDP within quarter
# 2. GovSpend - discretionary policy, less responsive within quarter
# 3. GDP - output responds to policy with some delay
# 4. CPI - inflation responds to output and policy
# 5. IntRate - monetary policy responds to all variables

svar_data = df[['net_revenue_level', 'gov_spending_diff', 'log_gdp_diff',
                'cpi_diff', 'interest_rate_level']].dropna()

# Short names (Stock & Watson style)
svar_data.columns = ['NetRev', 'GovSpend', 'GDP', 'CPI', 'IntRate']

n_obs = len(svar_data)
n_vars = len(svar_data.columns)

print("=" * 80)
print("STRUCTURAL VAR MODEL - BLANCHARD-PEROTTI IDENTIFICATION")
print("=" * 80)
print(f"Variables: NetRev, GovSpend, GDP(Δ), CPI(Δ), IntRate")
print(f"Observations: {n_obs}")
print("=" * 80)

# ============================================
# FIT REDUCED-FORM VAR
# ============================================

model = VAR(svar_data)
max_lags_to_test = min(4, int((n_obs - 1) / n_vars) - 1)
lag_order_results = model.select_order(maxlags=max_lags_to_test)
optimal_lag = lag_order_results.bic

var_model = model.fit(optimal_lag)

print(f"\n✓ Reduced-Form VAR({optimal_lag}) Estimated")
print(f"  Observations used: {var_model.nobs}")
print(f"  AIC: {var_model.aic:.2f}")
print(f"  BIC: {var_model.bic:.2f}")

# ============================================
# STRUCTURAL IDENTIFICATION - AB-MODEL (SHORT-RUN RESTRICTIONS)
# ============================================

print("\n" + "=" * 80)
print("A. STRUCTURAL IDENTIFICATION: AB-MODEL")
print("=" * 80)
print("\nBlanchard-Perotti Ordering (Short-Run Restrictions):")
print("  1. NetRev    - Tax revenue (automatic stabilizers)")
print("  2. GovSpend  - Government spending (discretionary fiscal)")
print("  3. GDP       - Output (responds to policy)")
print("  4. CPI       - Inflation (responds to output)")
print("  5. IntRate   - Interest rate (monetary policy response)")
print("\nInstitutional Restrictions:")
print("  • Tax revenue responds automatically to GDP within quarter")
print("  • Gov spending does not respond to GDP within quarter")
print("  • GDP responds to fiscal shocks with lag")
print("  • Inflation responds to output and policy")
print("  • Monetary policy responds to all variables")
print("=" * 80)

# Get residual covariance matrix
Sigma = var_model.sigma_u

# Cholesky decomposition for structural identification
P = cholesky(Sigma, lower=True)

print("\nReduced-Form Residual Covariance Matrix (Σ):")
print("-" * 80)
sigma_df = pd.DataFrame(Sigma, 
                        index=svar_data.columns,
                        columns=svar_data.columns)
print(sigma_df.round(6).to_string())

print("\n" + "-" * 80)
print("Structural Impact Matrix (B) - Cholesky Decomposition:")
print("-" * 80)
B_matrix_df = pd.DataFrame(P,
                           index=svar_data.columns,
                           columns=svar_data.columns)
print(B_matrix_df.round(6).to_string())
print("-" * 80)

# ============================================
# STRUCTURAL IMPULSE RESPONSE FUNCTIONS
# ============================================

irf_periods = min(12, n_obs // 2)
irf = var_model.irf(irf_periods)

# Compute structural IRFs by multiplying reduced-form IRFs with B
structural_irfs = np.zeros((irf_periods, n_vars, n_vars))
for t in range(irf_periods):
    structural_irfs[t, :, :] = irf.irfs[t, :, :] @ P

print("\n✓ Structural IRFs computed for {} periods".format(irf_periods))

# ============================================
# B. KEY STRUCTURAL IMPULSE RESPONSES (EXACT STOCK & WATSON STYLE)
# ============================================

print("\n" + "=" * 80)
print("B. IMPULSE RESPONSE FUNCTIONS FROM THE STRUCTURAL VAR")
print("=" * 80)

# Define specific IRFs to plot (as requested)
key_irfs = [
    ('GovSpend', 'GDP', 'Government Spending Shock'),
    ('GovSpend', 'CPI', 'Government Spending Shock'),
    ('NetRev', 'GDP', 'Tax Revenue Shock'),
    ('IntRate', 'CPI', 'Interest Rate Shock'),
]

# Create 2x2 subplot (Stock & Watson style)
fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=[
        'Response of GDP to<br>Government Spending Shock',
        'Response of CPI to<br>Government Spending Shock',
        'Response of GDP to<br>Tax Revenue Shock',
        'Response of CPI to<br>Interest Rate Shock'
    ],
    vertical_spacing=0.15,
    horizontal_spacing=0.12
)

variables = svar_data.columns.tolist()
periods = list(range(irf_periods))

plot_positions = [(1,1), (1,2), (2,1), (2,2)]

for idx, (impulse_var, response_var, shock_name) in enumerate(key_irfs):
    row, col = plot_positions[idx]
    
    impulse_idx = variables.index(impulse_var)
    response_idx = variables.index(response_var)
    
    irf_values = structural_irfs[:, response_idx, impulse_idx]
    
    # Add IRF line (black solid)
    fig.add_trace(
        go.Scatter(
            x=periods,
            y=irf_values,
            mode='lines',
            line=dict(color='black', width=2),
            showlegend=False,
            hovertemplate='<b>Lag %{x}</b><br>Response: %{y:.4f}<extra></extra>'
        ),
        row=row, col=col
    )
    
    # Add confidence bands (gray dotted lines)
    stderr = np.std(irf_values) / np.sqrt(len(irf_values))
    upper_band = irf_values + 1.96 * stderr
    lower_band = irf_values - 1.96 * stderr
    
    fig.add_trace(
        go.Scatter(
            x=periods,
            y=upper_band,
            mode='lines',
            line=dict(color='gray', width=1, dash='dot'),
            showlegend=False,
            hoverinfo='skip'
        ),
        row=row, col=col
    )
    
    fig.add_trace(
        go.Scatter(
            x=periods,
            y=lower_band,
            mode='lines',
            line=dict(color='gray', width=1, dash='dot'),
            showlegend=False,
            hoverinfo='skip'
        ),
        row=row, col=col
    )
    
    # Add zero line
    fig.add_hline(y=0, line_dash="solid", line_color="gray", 
                 line_width=0.5, row=row, col=col)

# Update layout (EXACT Stock & Watson style)
fig.update_layout(
    title={
        'text': '<b>Impulse Responses in the Structural VAR</b><br>' +
                f'<sub>Blanchard-Perotti Identification</sub>',
        'y':0.97,
        'x':0.5,
        'xanchor': 'center',
        'font': dict(size=16, color='black', family='Times New Roman')
    },
    height=800,
    width=1200,
    plot_bgcolor='white',
    paper_bgcolor='white',
    font=dict(size=9, family='Times New Roman'),
    margin=dict(l=60, r=40, t=100, b=60)
)

# Update axes (EXACT Stock & Watson style)
fig.update_xaxes(
    title_text="Lag",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.update_yaxes(
    title_text="Percent",
    showgrid=False,
    showline=True,
    linewidth=1,
    linecolor='black',
    mirror=True,
    ticks='outside',
    tickfont=dict(size=8)
)

fig.show()

# ============================================
# C. VARIANCE DECOMPOSITIONS FROM THE STRUCTURAL VAR
# ============================================

print("\n" + "=" * 80)
print("C. VARIANCE DECOMPOSITIONS FROM THE STRUCTURAL VAR")
print("=" * 80)

forecast_horizons = [h for h in [1, 4, 8, 12] if h <= irf_periods]

for var_idx, var_name in enumerate(variables):
    print(f"\nC.{var_idx+1}. Variance Decomposition of {var_name}")
    print("-" * 80)
    print(f"{'Forecast':<12} {'Forecast':<18} {'Variance Decomposition'}")
    print(f"{'Horizon':<12} {'Standard Error':<18} {'(Percentage Points)'}")
    print(f"{'':<30} {' '.join([f'{v:>8}' for v in variables])}")
    print("-" * 80)
    
    for h in forecast_horizons:
        # Calculate MSE at horizon h using structural IRFs
        mse = np.sum([structural_irfs[i, var_idx, :] ** 2 for i in range(h)], axis=0)
        total_mse = np.sum(mse)
        
        # Variance decomposition (percentage)
        decomp = (mse / total_mse) * 100
        
        # Standard error
        se = np.sqrt(total_mse)
        
        print(f"{h:<12} {se:<18.2f} {' '.join([f'{d:>8.0f}' for d in decomp])}")
    
    print("-" * 80)

# ============================================
# SUMMARY TABLE
# ============================================

print("\n" + "=" * 80)
print("SUMMARY - STRUCTURAL VAR MODEL")
print("=" * 80)
print(f"Identification: AB-Model (Blanchard-Perotti)")
print(f"Lag Order: {optimal_lag}")
print(f"Observations: {var_model.nobs}")
print(f"AIC: {var_model.aic:.2f}")
print(f"BIC: {var_model.bic:.2f}")
print(f"HQIC: {var_model.hqic:.2f}")
print(f"IRF Periods: {irf_periods}")
print("\nVariable Ordering (Blanchard-Perotti):")
print("  1. NetRev    - Tax revenue")
print("  2. GovSpend  - Government spending")
print("  3. GDP       - Output (first difference)")
print("  4. CPI       - Inflation (first difference)")
print("  5. IntRate   - Interest rate")
print("\nKey Structural Shocks Analyzed:")
print("  • Government spending → GDP, Inflation")
print("  • Tax revenue → GDP")
print("  • Interest rate → Inflation")
print("=" * 80)

# ============================================
# EXPORT RESULTS
# ============================================

# Export structural matrix
B_matrix_df.to_csv('svar_structural_matrix_B.csv')
print("\n✓ Structural matrix (B) saved to 'svar_structural_matrix_B.csv'")

# Export covariance matrix
sigma_df.to_csv('svar_residual_covariance.csv')
print("✓ Residual covariance matrix saved to 'svar_residual_covariance.csv'")

# Export structural IRFs for key relationships
for impulse_var, response_var, shock_name in key_irfs:
    impulse_idx = variables.index(impulse_var)
    response_idx = variables.index(response_var)
    irf_values = structural_irfs[:, response_idx, impulse_idx]
    
    irf_df = pd.DataFrame({
        'Lag': list(range(irf_periods)),
        'IRF': irf_values
    })
    filename = f'svar_irf_{impulse_var}_to_{response_var}.csv'
    irf_df.to_csv(filename, index=False)
    print(f"✓ IRF {impulse_var} → {response_var} saved to '{filename}'")

# Export variance decompositions
for var_idx, var_name in enumerate(variables):
    fevd_table_data = []
    for h in forecast_horizons:
        mse = np.sum([structural_irfs[i, var_idx, :] ** 2 for i in range(h)], axis=0)
        total_mse = np.sum(mse)
        decomp = (mse / total_mse) * 100
        se = np.sqrt(total_mse)
        
        row = {'Horizon': h, 'Std_Error': se}
        for v_idx, v_name in enumerate(variables):
            row[v_name] = decomp[v_idx]
        fevd_table_data.append(row)
    
    fevd_df = pd.DataFrame(fevd_table_data)
    fevd_df.to_csv(f'svar_fevd_{var_name}.csv', index=False)
    print(f"✓ FEVD table for {var_name} saved to 'svar_fevd_{var_name}.csv'")

print("\n" + "=" * 80)
print("✓ STRUCTURAL VAR ANALYSIS COMPLETE (STOCK & WATSON STYLE)")
print("=" * 80)
```

The Blanchard-Perotti SVAR identifies fiscal policy shocks by assuming that taxes respond automatically to GDP within the quarter, while government spending does not, and the system is ordered so that fiscal variables affect GDP before inflation and interest rates react. The structural impact matrix shows that Net Revenue shocks have strong immediate effects on government spending (large negative coefficient), meaning that when tax revenue changes unexpectedly, the fiscal authority adjusts spending instantly and strongly, consistent with budget constraints. Government spending shocks, in turn, have a positive contemporaneous effect on GDP (0.000356), capturing the short-run fiscal multiplier. GDP shocks reduce inflation slightly on impact, while CPI responds strongly to its own shock (0.284), consistent with price rigidity followed by adjustment. Monetary policy reacts contemporaneously to all shocks—especially inflation (0.0055) and its own shocks—showing clear policy responsiveness. Overall, the SVAR structure indicates that fiscal shocks transmit quickly to output, inflation adjusts after real activity responds, and interest rates behave as an active policy instrument reacting to both fiscal and macroeconomic disturbances. The structural IRFs therefore capture cleaner, policy-relevant responses compared to reduced-form VARs. The SVAR results show that a government spending shock initially boosts GDP strongly, but the effect quickly becomes negative after a few periods, indicating a short-lived fiscal multiplier followed by contraction—likely due to crowding-out or delayed budget adjustments. The same spending shock raises CPI moderately in the short run, showing a temporary inflationary effect that fades and then rebounds slightly, reflecting cost-push and demand-pull channels. A tax revenue shock (interpreted as a contractionary fiscal shock) causes GDP to rise mildly at first—consistent with automatic stabilizer behavior where higher tax collection reflects economic strength—before GDP declines later, indicating a delayed contractionary effect. Finally, an interest rate shock causes CPI to fall sharply and persistently, confirming that monetary tightening reduces inflation with a lag, followed by a gradual return toward baseline as policy influence fades. Overall, the IRFs suggest that fiscal shocks have short-lived real effects, monetary shocks strongly influence inflation, and the economy adjusts differently to discretionary spending versus automatic tax changes.The structural FEVD shows a system where fiscal policy variables (NetRev and GovSpend) dominate short-run fluctuations, but monetary variables and inflation gain importance over longer horizons. Net Revenue is overwhelmingly driven by its own shocks (100% → 73%), meaning tax revenue is mostly determined by internal fiscal conditions, with GDP and CPI gaining small influence over time. Government spending is initially almost entirely determined by its own innovations (97%), but by 12 periods output shocks explain 40% of its movements and interest rate shocks about 10%, indicating that economic activity and monetary policy increasingly influence spending decisions. GDP is largely driven by government spending and its own shocks in the short run (≈50% each), but in the long run CPI shocks dominate, explaining over 50–65% of the variation—showing inflation becomes the key driver of real activity over time. CPI itself is mostly self-driven (90% → 48%) but becomes significantly affected by government spending (up to 28%) and interest rates (up to 12%), consistent with fiscal-monetary pass-through into inflation. Interest rates are initially determined by fiscal shocks—mainly government spending (71%)—but over time GDP (34%) and CPI (20%) become the main drivers, confirming an active monetary policy that responds strongly to macroeconomic conditions. Overall, the FEVD indicates a fiscal-dominant short run and a monetary-inflation dominant long run, where government spending and inflation are the key sources of macroeconomic fluctuations.

# **Policy Implications**
1. **Active Monetary Policy**
Interest rate changes powerfully control inflation and output. Policymakers should adjust rates proactively to counter inflation and prevent overheating using rule-based approaches for credibility.
2. **Inflation Stabilization Priority**
CPI shocks drive long-run GDP variance. Tighten monetary policy when inflation rises and maintain credibility through transparent communication and stable expectations.
3. **Strategic Fiscal Policy**
Government spending boosts GDP initially but causes later corrections. Use targeted, productivity-enhancing projects rather than broad stimulus. Avoid abrupt fiscal shocks to prevent inflation and crowding-out.
4. **Revenue Policy Design**
Tax changes are ineffective short-run stabilizers. Focus on predictable tax systems, broader bases, and automatic stabilizers to fund strategic investments without disruptive hikes.
5. **Fiscal-Monetary Coordination**
Deep policy interconnections require alignment. Synchronize fiscal expansion, inflation control, and monetary tightening through joint forecasting and decision-making to avoid policy conflicts.
6. **Output Stabilization**
Stabilize GDP through: (1) disciplined fiscal management to limit spending-driven swings, and (2) strong inflation control for medium-term growth. Balance countercyclical spending with inflation-sensitive monetary action.
7. **Long-Run Sustainability**
Monetary policy increasingly matters over time. Design sustainable fiscal paths with stable spending, realistic budgets, and awareness of long-run monetary conditions to enhance shock resilience.



**Refernce list**

Box, G. E. P., & Jenkins, G. M. (1976). Time series analysis: Forecasting and control (Rev. ed.). Holden-Day.

Chow, G. C., & Lin, A. L. (1971). Best linear unbiased interpolation, distribution, and extrapolation of time series by related series. The Review of Economics and Statistics, 53(4), 372-375. https://doi.org/10.2307/1928739

Dickey, D. A., & Fuller, W. A. (1981). Likelihood ratio statistics for autoregressive time series with a unit root. Econometrica, 49(4), 1057-1072. https://doi.org/10.2307/1912517

Enders, W. (2015). Applied econometric time series (4th ed.). Wiley.

Hyndman, R. J., & Athanasopoulos, G. (2018). Forecasting: Principles and practice (2nd ed.). OTexts.

Kwiatkowski, D., Phillips, P. C. B., Schmidt, P., & Shin, Y. (1992). Testing the null hypothesis of stationarity against the alternative of a unit root. Journal of Econometrics, 54(1-3), 159-178. https://doi.org/10.1016/0304-4076(92)90104-Y

Lütkepohl, H. (2005). New introduction to multiple time series analysis. Springer.
Sims, C. A. (1980). Macroeconomics and reality. Econometrica, 48(1), 1-48. https://doi.org/10.2307/1912017

International Monetary Fund. (2020). Pakistan: Staff report for the 2019 Article IV consultation. IMF Country Report No. 20/1. Washington, DC: International Monetary Fund.

Khan, M. A., & Ahmed, A. (2021). Macroeconomic dynamics and fiscal sustainability in Pakistan: A time series analysis. Journal of Asian Economics, 76, 101362. https://doi.org/10.1016/j.asieco.2021.101362

Lütkepohl, H. (2019). Structural vector autoregressive analysis for cointegrated variables. In Handbook of research methods and applications in empirical macroeconomics (pp. 139-164). Edward Elgar Publishing.

Ramey, V. A. (2019). Ten years after the financial crisis: What have we learned from the renaissance in fiscal research? Journal of Economic Perspectives, 33(2), 89-114. https://doi.org/10.1257/jep.33.2.89

Sims, C. A. (2022). Macroeconomics and methodology. Journal of Economic Perspectives, 36(2), 87-107. https://doi.org/10.1257/jep.36.2.87

Stiglitz, J. E. (2018). Where modern macroeconomics went wrong. Oxford Review of Economic Policy, 34(1-2), 70-106. https://doi.org/10.1093/oxrep/grx057

Stock, J. H., & Watson, M. W. (2020). Introduction to econometrics (4th ed.). Pearson Education.
World Bank. (2021). Pakistan development update. Washington, DC: World Bank Group.

